import streamlit as st
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support
from sklearn.feature_selection import SelectKBest, f_classif
from imblearn.over_sampling import SMOTE
from scipy.stats import entropy, zscore, skew, kurtosis
import matplotlib.pyplot as plt
import hashlib

# ------------------------------
# 1. H√†m lo·∫°i b·ªè ho·∫∑c thay th·∫ø outliers
# ------------------------------
@st.cache_data
def handle_outliers(window_data):
    """X·ª≠ l√Ω outliers b·∫±ng Z-score v√† thay th·∫ø b·∫±ng trung v·ªã."""
    arr = np.array(window_data, dtype=float)
    if len(arr) < 2:
        return arr.tolist()
    
    z_scores = np.abs(zscore(arr, ddof=1))
    median_val = np.median(arr)
    arr[z_scores > 3] = median_val
    return arr.tolist()

# ------------------------------
# H√†m t√≠nh micro-patterns
# ------------------------------
def calculate_streaks(binary_seq):
    if not binary_seq:
        return 0
    current_streak = 1
    max_streak = 1
    for i in range(1, len(binary_seq)):
        if binary_seq[i] == binary_seq[i-1]:
            current_streak += 1
            max_streak = max(max_streak, current_streak)
        else:
            current_streak = 1
    return max_streak

def calculate_alternations(binary_seq):
    if len(binary_seq) < 2:
        return 0
    alternations = sum(1 for i in range(1, len(binary_seq)) if binary_seq[i] != binary_seq[i-1])
    return alternations / (len(binary_seq) - 1)

def calculate_autocorrelation(binary_seq, lag=1):
    if len(binary_seq) < lag + 1:
        return 0
    mean = np.mean(binary_seq)
    var = np.var(binary_seq)
    if var == 0:
        return 0
    ac = sum((binary_seq[i] - mean) * (binary_seq[i+lag] - mean) for i in range(len(binary_seq)-lag)) / (var * len(binary_seq))
    return ac

# ------------------------------
# H√†m t√≠nh bias ·∫©n
# ------------------------------
def calculate_bias_metrics(binary_seq):
    if len(binary_seq) < 2:
        return 0, 0, 0
    var = np.var(binary_seq)
    sk = skew(binary_seq)
    kur = kurtosis(binary_seq)
    return var, sk, kur

# ------------------------------
# 2. H√†m t·∫°o ƒë·∫∑c tr∆∞ng n√¢ng cao
# ------------------------------
@st.cache_data(hash_funcs={list: lambda x: hashlib.sha256(str(x).encode()).hexdigest()})
def create_advanced_features(history, window=5):
    encode = {"T√†i": 1, "X·ªâu": 0}
    history_num = [encode[r] for r in history]

    X, y = [], []
    for i in range(window, len(history_num)):
        basic_feats = history_num[i-window:i]
        basic_feats_clean = handle_outliers(basic_feats)

        counts = np.bincount(basic_feats_clean, minlength=2)
        probabilities = counts / counts.sum()
        entropy_val = entropy(probabilities, base=2)

        momentum = np.mean(np.diff(basic_feats_clean[-3:])) if len(basic_feats_clean) >= 2 else 0
        streaks = calculate_streaks(basic_feats_clean)
        alternations = calculate_alternations(basic_feats_clean)
        autocorr = calculate_autocorrelation(basic_feats_clean)
        var, sk, kur = calculate_bias_metrics(basic_feats_clean)

        features = basic_feats_clean + [entropy_val, momentum, streaks, alternations, autocorr, var, sk, kur]
        X.append(features)
        y.append(history_num[i])

    X = np.array(X)
    y = np.array(y)

    # Feature selection
    if len(X) > 0:
        selector = SelectKBest(f_classif, k=min(10, X.shape[1]))
        X = selector.fit_transform(X, y)

    return X, y

# ------------------------------
# 3. Ph√¢n t√≠ch ƒë·ªô ng·∫´u nhi√™n
# ------------------------------
@st.cache_data(hash_funcs={list: lambda x: hashlib.sha256(str(x).encode()).hexdigest()})
def analyze_randomness_window(history, window=5):
    if len(history) < window:
        return "üî¥ Ch∆∞a ƒë·ªß d·ªØ li·ªáu."
    encode = {"T√†i": 1, "X·ªâu": 0}
    last_window = [encode[r] for r in history[-window:]]
    last_window = handle_outliers(last_window)
    counts = np.bincount(last_window, minlength=2)
    probabilities = counts / counts.sum()
    ent_val = entropy(probabilities, base=2)
    
    streaks = calculate_streaks(last_window)
    alternations = calculate_alternations(last_window)
    autocorr = calculate_autocorrelation(last_window)
    var, sk, kur = calculate_bias_metrics(last_window)
    
    base_status = f"üî¥ Entropy: {ent_val:.2f}. "
    if ent_val > 0.95:
        base_status += "C·ª±c k·ª≥ ng·∫´u nhi√™n! "
    elif ent_val > 0.85:
        base_status += "Kh√° ng·∫´u nhi√™n. "
    elif ent_val > 0.70:
        base_status += "C√≥ m·ªôt s·ªë pattern. "
    else:
        base_status += "Pattern r√µ r√†ng. "
    
    micro_status = f"üîç Micro-patterns: Max Streak={streaks}, Alternations={alternations:.2f}, Autocorr={autocorr:.2f}. "
    bias_status = f"üìä Bias: Var={var:.2f}, Skew={sk:.2f}, Kurt={kur:.2f}."
    
    return base_status + micro_status + bias_status

# ------------------------------
# 4. D·ª± ƒëo√°n v√°n ti·∫øp theo
# ------------------------------
def predict_next_ensemble(models, weights, history, window=5, confidence_threshold=0.65):
    encode = {"T√†i": 1, "X·ªâu": 0}
    if len(history) < window or not models:
        return "Ch∆∞a ƒë·ªß d·ªØ li·ªáu", 0.5, "Ch∆∞a ƒë·ªß", np.nan

    last_window = [encode[r] for r in history[-window:]]
    last_window = handle_outliers(last_window)

    counts = np.bincount(last_window, minlength=2)
    probabilities = counts / counts.sum()
    entropy_val = entropy(probabilities, base=2)
    momentum = np.mean(np.diff(last_window[-3:])) if len(last_window) >= 2 else 0
    streaks = calculate_streaks(last_window)
    alternations = calculate_alternations(last_window)
    autocorr = calculate_autocorrelation(last_window)
    var, sk, kur = calculate_bias_metrics(last_window)

    final_feats = last_window + [entropy_val, momentum, streaks, alternations, autocorr, var, sk, kur]

    # Adaptive strategy
    adaptive_threshold = confidence_threshold
    if entropy_val > 0.85:
        adaptive_threshold = 0.70
    if kur > 0:
        adaptive_threshold = 0.70
    if entropy_val > 0.85 and abs(sk) < 0.1:
        majority = "T√†i" if sum(last_window) > window / 2 else "X·ªâu"
        return majority, 0.5, "Fallback do nhi·ªÖu cao ‚ö†Ô∏è", entropy_val

    probs = []
    for model in models:
        try:
            prob = model.predict_proba([final_feats])[0][1]
        except:
            prob = 0.5
        probs.append(prob)
    probs = np.array(probs)
    final_prob_tai = np.clip(np.dot(weights, probs), 0.0, 1.0)

    if final_prob_tai > 0.5:
        pred, prob = "T√†i", final_prob_tai
    else:
        pred, prob = "X·ªâu", 1 - final_prob_tai

    confidence_status = "ƒê√°ng tin c·∫≠y ‚úÖ"
    if prob < adaptive_threshold:
        confidence_status = f"Th·∫•p! (<{adaptive_threshold:.0%}) ‚ö†Ô∏è"
        pred = "KH√îNG D·ª∞ ƒêO√ÅN"

    return pred, prob, confidence_status, entropy_val

# ------------------------------
# H√†m t√≠nh probs_list cho bi·ªÉu ƒë·ªì
# ------------------------------
@st.cache_data(hash_funcs={list: lambda x: hashlib.sha256(str(x).encode()).hexdigest()})
def compute_probs_list(history, window, _models, _weights):
    probs_list = []
    for i in range(window, len(history)):
        history_slice = history[:i]
        _, prob_tmp, _, _ = predict_next_ensemble(_models, _weights, history_slice, window, confidence_threshold=0.0)
        probs_list.append(prob_tmp)
    return probs_list

# ------------------------------
# 5. Streamlit App
# ------------------------------
st.set_page_config(page_title="üé≤ AI D·ª± ƒëo√°n T√†i X·ªâu N√¢ng Cao", layout="wide")
st.title("üé≤ AI D·ª± ƒëo√°n T√†i X·ªâu N√¢ng Cao")
st.markdown("**Meta-Ensemble (5 models, weights ƒë·ªông) | Micro-patterns + Bias + Adaptive Strategy + T·ªëi ∆Øu cho Small Data**")

# Session state
if "history" not in st.session_state: 
    st.session_state.history = []
if "models" not in st.session_state: 
    st.session_state.models = None
if "weights" not in st.session_state: 
    st.session_state.weights = None
if "window" not in st.session_state: 
    st.session_state.window = 7
if "prev_hash" not in st.session_state:
    st.session_state.prev_hash = ""
if "force_train" not in st.session_state:
    st.session_state.force_train = False
window = st.session_state.window

# Gi·ªõi h·∫°n history
max_history = 1000
if len(st.session_state.history) > max_history:
    st.session_state.history = st.session_state.history[-max_history:]

# --- Nh·∫≠p k·∫øt qu·∫£ v√† qu·∫£n l√Ω d·ªØ li·ªáu ---
st.subheader("1. Nh·∫≠p K·∫øt Qu·∫£ V√°n Ch∆°i v√† Qu·∫£n L√Ω D·ªØ Li·ªáu")
col1, col2, col3, col4 = st.columns(4)
with col1:
    if st.button("üéØ T√†i"):
        st.session_state.history.append("T√†i")
with col2:
    if st.button("üéØ X·ªâu"):
        st.session_state.history.append("X·ªâu")
with col3:
    if st.button("üõ†Ô∏è Hu·∫•n Luy·ªán M√¥ H√¨nh"):
        st.session_state.force_train = True
with col4:
    if st.button("üóëÔ∏è X√≥a To√†n B·ªô D·ªØ Li·ªáu"):
        st.session_state.history = []
        st.session_state.models = None
        st.session_state.weights = None
        st.session_state.prev_hash = ""
        st.session_state.force_train = False
        st.success("ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu.")

# T√≠nh hash history
def hash_history(hist):
    return hashlib.sha256(str(hist).encode()).hexdigest()

current_hash = hash_history(st.session_state.history)

# --- Ph√¢n t√≠ch l·ªãch s·ª≠ ---
st.subheader("2. Ph√¢n T√≠ch L·ªãch S·ª≠")
if st.session_state.history:
    st.write("L·ªãch s·ª≠ k·∫øt qu·∫£ (m·ªõi nh·∫•t cu·ªëi):", st.session_state.history)
    st.markdown(analyze_randomness_window(st.session_state.history, window))
    count_tai = st.session_state.history.count("T√†i")
    count_xiu = st.session_state.history.count("X·ªâu")
    total = len(st.session_state.history)
    st.write(f"T√†i: {count_tai} ({count_tai/total:.2%}) | X·ªâu: {count_xiu} ({count_xiu/total:.2%})")
else:
    st.info("Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch s·ª≠.")
