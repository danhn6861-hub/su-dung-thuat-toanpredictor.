import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import io
from datetime import datetime

st.set_page_config(page_title="AI D·ª± ƒëo√°n T√†i/X·ªâu N√¢ng Cao", layout="wide")

# ===== Sidebar =====
st.sidebar.markdown("""
### ‚ö†Ô∏è L∆∞u √ù
·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh ch·∫•t gi·∫£i tr√≠ v√† tham kh·∫£o. Kh√¥ng khuy·∫øn kh√≠ch s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch c·ªù b·∫°c ho·∫∑c ƒë·∫ßu t∆∞ th·ª±c t·∫ø.
""")

# ===== Session state =====
for key in ["history", "models", "ai_last_pred", "undo_stack", "pred_history"]:
    if key not in st.session_state:
        st.session_state[key] = []

# ===== H√†m t·∫°o ƒë·∫∑c tr∆∞ng (C·∫£i thi·ªán) =====
def create_features(history, windows=[3,6,9]):
    if len(history) < max(windows) + 1:
        return np.empty((0, len(windows)*2 + 3)), np.empty((0,))
    X, y = [], []
    states = {'T√†i':1, 'X·ªâu':0}
    for i in range(max(windows), len(history)):
        features = []
        for w in windows:
            recent = [states[x] for x in history[i-w:i]]
            features.extend([np.mean(recent), sum(recent)])  # Trung b√¨nh v√† t·ªïng
        # Th√™m ƒë·∫∑c tr∆∞ng m·ªõi: streak, ratio d√†i h·∫°n, entropy
        streak = 1
        for j in range(i-1, max(0, i-11), -1):  # Streak max 10 v√°n
            if history[j] != history[i-1]: break
            streak += 1
        long_ratio = sum(states[x] for x in history[max(0,i-20):i]) / min(20, i)
        entropy = -np.sum([p * np.log(p+1e-6) for p in [long_ratio, 1-long_ratio]])
        features.extend([streak, long_ratio, entropy])
        X.append(features)
        y.append(states[history[i]])
    return np.array(X), np.array(y)

# ===== Hu·∫•n luy·ªán model ri√™ng t·ª´ng model v√† Stacking (C·∫£i thi·ªán v·ªõi CV v√† validation) =====
@st.cache_resource
def train_models_individual(history):
    X, y = create_features(history)
    if len(X) < 10: return None  # C·∫ßn √≠t nh·∫•t 10 m·∫´u ƒë·ªÉ split
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    
    models = {
        'LogisticRegression': LogisticRegression(max_iter=500, solver='liblinear', class_weight='balanced'),
        'RandomForest': RandomForestClassifier(n_estimators=30, max_depth=3, min_samples_leaf=5, class_weight='balanced', random_state=42),
        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric="logloss", n_estimators=30, max_depth=2, learning_rate=0.05, scale_pos_weight=sum(y==0)/sum(y==1) if sum(y==1)>0 else 1)
    }
    
    for name, model in models.items():
        model.fit(X_train, y_train)
        # Ki·ªÉm tra CV score ƒë·ªÉ tr√°nh overfit
        cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
        st.write(f"{name} CV Accuracy: {np.mean(cv_scores):.2%}")
        # Ki·ªÉm tra val accuracy
        val_pred = model.predict(X_val)
        val_acc = accuracy_score(y_val, val_pred)
        st.write(f"{name} Val Accuracy: {val_acc:.2%}")
        if val_acc < 0.5: st.warning(f"{name} c√≥ th·ªÉ overfit ho·∫∑c underfit!")
    
    # Stacking v·ªõi c√°c model ƒë√£ hu·∫•n luy·ªán
    estimators = [(n,m) for n,m in models.items()]
    stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(class_weight='balanced'), cv=3)
    stack.fit(X_train, y_train)
    models['Stacking'] = stack
    return models

# ===== Pattern Detector 6 v√°n =====
def pattern_detector(history, window=6):
    if len(history) < window*2: return 0.5
    states = {'T√†i':1, 'X·ªâu':0}
    trans = np.zeros((2,2))
    for i in range(1,len(history)):
        prev, curr = states[history[i-1]], states[history[i]]
        trans[prev,curr] +=1
    trans /= np.sum(trans,axis=1,keepdims=True)+1e-6
    last_state = states[history[-1]]
    return trans[last_state,1]

# ===== D·ª± ƒëo√°n t·ª´ng model + t·ªïng h·ª£p (C·∫£i thi·ªán v·ªõi tr·ªçng s·ªë h·ªçc ƒë∆∞·ª£c) =====
def predict_next(models, history):
    if len(history) < 10 or models is None: return None, None
    X, y = create_features(history)  # Fixed: assign y
    latest = X[-1].reshape(1, -1)  # ƒê·∫∑c tr∆∞ng cu·ªëi c√πng
    
    preds = {}
    for name, model in models.items():
        if hasattr(model,"predict_proba"):
            prob = model.predict_proba(latest)[0][1]
        else:
            prob = float(model.predict(latest)[0])
        preds[name] = prob
    preds['Pattern Detector'] = pattern_detector(history)
    
    # H·ªçc tr·ªçng s·ªë t·ª´ data (s·ª≠ d·ª•ng LinearRegression tr√™n preds gi·∫£ tr√™n train)
    if len(X) > 1 and len(preds) > 1:
        # T·∫°o ma tr·∫≠n preds cho to√†n train (gi·∫£ l·∫≠p b·∫±ng c√°ch predict tr√™n X)
        model_preds = []
        for n, m in models.items():
            if n != 'Stacking':
                if hasattr(m, 'predict_proba'):
                    model_preds.append(m.predict_proba(X)[:,1])
                else:
                    model_preds.append(m.predict(X))
        pred_matrix = np.array(model_preds).T
        
        # Compute historical patterns correctly
        historical_patterns = []
        max_windows = 9  # From windows=[3,6,9]
        for i in range(max_windows, len(history)):
            hist_slice = history[:i]
            historical_patterns.append(pattern_detector(hist_slice))
        pred_matrix = np.hstack([pred_matrix, np.array(historical_patterns).reshape(-1, 1)])
        
        split = len(X)//2
        if split > 0:
            weight_model = LinearRegression().fit(pred_matrix[:split], y[:split])
            input_vec = [preds['LogisticRegression'], preds['RandomForest'], preds['XGBoost'], preds['Pattern Detector']]
            final_score = weight_model.predict(np.array([input_vec]))[0]
        else:
            final_score = preds.get('Stacking', 0.5)
    else:
        final_score = preds.get('Stacking', 0.5)
    
    return preds, np.clip(final_score, 0, 1)

# ===== Th√™m k·∫øt qu·∫£ + undo + t√≠nh accuracy =====
def add_result(result):
    st.session_state.undo_stack.append(st.session_state.history.copy())
    st.session_state.history.append(result)
    if len(st.session_state.history)>200:
        st.session_state.history=st.session_state.history[-200:]
    # C·∫≠p nh·∫≠t pred_history
    if st.session_state.ai_last_pred is not None:
        st.session_state.pred_history.append({'pred':st.session_state.ai_last_pred,'true':result})

def undo_last():
    if st.session_state.undo_stack:
        st.session_state.history = st.session_state.undo_stack.pop()
        if st.session_state.pred_history:
            st.session_state.pred_history.pop()

def get_accuracy():
    if not st.session_state.pred_history: return None
    correct = sum(1 for x in st.session_state.pred_history if x['pred']==x['true'])
    return correct/len(st.session_state.pred_history)

# ===== Export/Import =====
def export_history():
    df = pd.DataFrame({"K·∫øt qu·∫£": st.session_state.history})
    return df.to_csv(index=False).encode('utf-8')

def import_history(uploaded_file):
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.session_state.history = df["K·∫øt qu·∫£"].tolist()
        st.success("ƒê√£ import l·ªãch s·ª≠!")

# ===== Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n =====
def plot_prediction(preds):
    fig,ax=plt.subplots()
    names=list(preds.keys())
    values=[preds[n]*100 for n in names]
    colors=['blue','orange','green','purple','red','brown']
    ax.barh(names,values,color=colors[:len(names)])
    ax.set_xlim(0,100)
    ax.set_xlabel("X√°c su·∫•t T√†i (%)")
    ax.set_title("D·ª± ƒëo√°n t·ª´ng model & Pattern Detector")
    buf=io.BytesIO()
    fig.savefig(buf,format='png')
    buf.seek(0)
    st.image(buf)

# ===== Giao di·ªán =====
st.title("üéØ AI D·ª± ƒëo√°n T√†i/X·ªâu ‚Äì ML + Pattern Detector")

col1,col2 = st.columns(2)
with col1:
    if st.button("Nh·∫≠p T√†i"): add_result("T√†i")
    if st.button("Nh·∫≠p X·ªâu"): add_result("X·ªâu")
with col2:
    if st.button("‚Ü©Ô∏è Undo"): undo_last()
    uploaded_file=st.file_uploader("Import CSV",type='csv')
    if uploaded_file: import_history(uploaded_file)
    st.download_button("Export CSV",export_history(),f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")

st.divider()

# Hi·ªÉn th·ªã l·ªãch s·ª≠
if st.session_state.history:
    st.write("L·ªãch s·ª≠ g·∫ßn ƒë√¢y:", " ‚Üí ".join(st.session_state.history[-30:]))

# Hu·∫•n luy·ªán model
if st.button("‚öôÔ∏è Hu·∫•n luy·ªán model"):
    st.session_state.models = train_models_individual(st.session_state.history)
    st.success("ƒê√£ hu·∫•n luy·ªán xong!")

# D·ª± ƒëo√°n v√† hi·ªÉn th·ªã
if st.session_state.models and len(st.session_state.history)>=10:
    preds, final_score = predict_next(st.session_state.models, st.session_state.history)
    st.session_state.ai_last_pred = "T√†i" if final_score>=0.5 else "X·ªâu"
    st.subheader(f"üéØ D·ª± ƒëo√°n t·ªïng h·ª£p: {st.session_state.ai_last_pred} ({final_score:.2%})")
    st.caption("D·ª± ƒëo√°n chi ti·∫øt t·ª´ng model + Pattern Detector")
    for k,v in preds.items():
        st.write(f"**{k}** ‚Üí {v:.2%} ({'T√†i' if v>=0.5 else 'X·ªâu'})")
    plot_prediction(preds)

# Hi·ªÉn th·ªã t·ª∑ l·ªá th·∫Øng d·ª± ƒëo√°n
acc = get_accuracy()
if acc is not None:
    st.info(f"T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng sau {len(st.session_state.pred_history)} v√°n: {acc:.2%}")
