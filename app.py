# app.py - Fusion Pro (Hybrid + Improved) - Streamlit-ready (2025)
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import io, os, joblib
from datetime import datetime

# sklearn
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, brier_score_loss, confusion_matrix

# optional xgboost
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

# ----------------- Page config -----------------
st.set_page_config(page_title="Fusion Pro - AI T√†i/X·ªâu", layout="wide")
st.title("üîÆ Fusion Pro ‚Äî AI D·ª± ƒëo√°n T√†i / X·ªâu (Hybrid + Improved)")
st.markdown("**Giao di·ªán:** ƒë·∫πp + bi·ªÉu ƒë·ªì & metrics ‚Ä¢ **Hu·∫•n luy·ªán:** ch·ªâ khi b·∫°n nh·∫•n n√∫t ‚Ä¢ **Ch·∫°y m∆∞·ª£t tr√™n Streamlit Cloud**")
st.caption("‚ö†Ô∏è ·ª®ng d·ª•ng ch·ªâ ph·ª•c v·ª• nghi√™n c·ª©u/h·ªçc t·∫≠p. Kh√¥ng khuy·∫øn kh√≠ch c·ªù b·∫°c.")

# ----------------- Constants & init -----------------
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
MODEL_PATH = "/tmp/fusion_pro_model.joblib"  # fallback path
HISTORY_PATH = "/tmp/fusion_pro_history.csv"

if "history" not in st.session_state:
    st.session_state.history = []
if "ai_conf" not in st.session_state:
    st.session_state.ai_conf = []
if "models" not in st.session_state:
    st.session_state.models = None
if "ai_last_pred" not in st.session_state:
    st.session_state.ai_last_pred = None
if "undo_stack" not in st.session_state:
    st.session_state.undo_stack = []
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

# ----------------- Utilities -----------------
def save_state_model(models, path=MODEL_PATH):
    try:
        joblib.dump(models, path)
        return True
    except Exception:
        return False

def load_state_model(path=MODEL_PATH):
    if os.path.exists(path):
        try:
            return joblib.load(path)
        except Exception:
            return None
    return None

def export_history_csv_bytes():
    df = pd.DataFrame({"K·∫øt qu·∫£": st.session_state.history})
    return df.to_csv(index=False).encode("utf-8")

# ----------------- Feature engineering -----------------
def create_features(history, window=6):
    if len(history) <= window:
        return np.empty((0, window + 2)), np.empty((0,))
    X = []
    y = []
    for i in range(window, len(history)):
        window_slice = history[i-window:i]
        base = [1 if x == "T√†i" else 0 for x in window_slice]
        tai_ratio = sum(base) / window
        changes = sum(base[j] != base[j-1] for j in range(1,len(base)))
        change_ratio = changes / max(1, (window-1))
        # current streak
        last = base[-1]
        streak = 1
        for j in range(len(base)-2, -1, -1):
            if base[j] == last:
                streak += 1
            else:
                break
        # last3 count
        last3 = sum(base[-3:]) if len(base) >=3 else sum(base)
        features = base + [tai_ratio, change_ratio, streak, last3]
        X.append(features)
        y.append(1 if history[i] == "T√†i" else 0)
    return np.array(X, dtype=float), np.array(y, dtype=int)

# ----------------- Pattern detector -----------------
def pattern_detector(history, lookback=8):
    if len(history) < 3:
        return 0.5
    recent = history[-lookback:] if len(history) >= lookback else history[:]
    tai_recent = sum(1 for x in recent if x == "T√†i")
    base_prob = tai_recent / len(recent)
    # streak detection
    max_streak = 1
    cur = 1
    for i in range(1, len(recent)):
        if recent[i] == recent[i-1]:
            cur += 1
            max_streak = max(max_streak, cur)
        else:
            cur = 1
    streak_factor = min(max_streak / 4.0, 1.0)
    if streak_factor > 0.5:
        adjusted = 1.0 - base_prob
    else:
        adjusted = 0.5
    return float(np.clip(adjusted, 0.1, 0.9))

# ----------------- Model training (Fusion) -----------------
@st.cache_resource
def train_fusion(history_tuple, ai_conf_tuple, use_xgb=True, cache_key=None):
    # history & weights
    history = list(history_tuple)
    ai_conf = list(ai_conf_tuple)
    xgb = None

    if len(history) < 12:  # require more data for robust hybrid
        return None

    X, y = create_features(history, window=6)
    if X.shape[0] < 8 or len(np.unique(y)) < 2:
        return None

    # noise injection to reduce exact memorization
    X = X + np.random.normal(0, 0.03, X.shape)

    # sample weights prefer recent but moderate
    recent_weight = np.linspace(0.3, 1.0, len(y))
    if ai_conf and len(ai_conf) >= len(y):
        combined = recent_weight * np.array(ai_conf[-len(y):], dtype=float)
    else:
        combined = recent_weight
    combined = np.clip(combined, 0.2, 2.0)

    # TimeSeries CV
    n_splits = min(4, max(2, X.shape[0] // 8))
    tscv = TimeSeriesSplit(n_splits=n_splits)

    # Logistic with regularization
    lr = LogisticRegressionCV(cv=tscv, max_iter=1200, class_weight='balanced', scoring='accuracy', random_state=RANDOM_SEED)

    # RandomForest tuned to avoid overfit
    rf = RandomForestClassifier(n_estimators=80, max_depth=6, min_samples_split=6, min_samples_leaf=2,
                                class_weight='balanced', n_jobs=1, random_state=RANDOM_SEED)

    learners = [('lr', lr), ('rf', rf)]

    # Optional XGBoost with fallback
    if use_xgb and HAS_XGB:
        try:
            xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=80, random_state=RANDOM_SEED, n_jobs=1)
            learners.append(('xgb', xgb))
        except Exception:
            xgb = None

    # Fit models
    try:
        lr.fit(X, y, sample_weight=combined)
    except Exception:
        lr.fit(X, y)
    rf.fit(X, y, sample_weight=combined)
    if xgb is not None:
        try:
            xgb.fit(X, y, sample_weight=combined)
        except Exception:
            try:
                xgb.fit(X, y)
            except Exception:
                xgb = None

    # Calibrate RF prob if possible
    try:
        calibrated_rf = CalibratedClassifierCV(base_estimator=rf, cv='prefit').fit(X, y)
    except Exception:
        calibrated_rf = rf

    estimators_voting = [('lr', lr), ('rf', calibrated_rf)]
    if xgb is not None:
        estimators_voting.append(('xgb', xgb))

    voting = VotingClassifier(estimators=estimators_voting, voting='soft', n_jobs=1)
    voting.fit(X, y)

    # Stacking (fallback to voting on exception)
    try:
        stack_estimators = [('lr', lr), ('rf', rf)]
        if xgb is not None:
            stack_estimators.append(('xgb', xgb))
        stack = StackingClassifier(estimators=stack_estimators, final_estimator=LogisticRegression(max_iter=800), passthrough=True, n_jobs=1)
        stack.fit(X, y)
    except Exception:
        stack = voting

    # quick metrics
    metrics = {}
    if X.shape[0] > 20:
        split = int(0.8 * len(X))
        X_tr, X_te = X[:split], X[split:]
        y_tr, y_te = y[:split], y[split:]
        try:
            pred = voting.predict(X_te)
            metrics['voting_acc'] = float(accuracy_score(y_te, pred))
        except Exception:
            metrics['voting_acc'] = None
        try:
            pprob = voting.predict_proba(X_te)[:, 1]
            metrics['voting_brier'] = float(brier_score_loss(y_te, pprob))
        except Exception:
            metrics['voting_brier'] = None

    return {
        "voting": voting,
        "stacking": stack,
        "lr": lr,
        "rf": rf,
        "xgb": xgb,
        "metrics": metrics
    }

# ----------------- Prediction combining model + pattern + rolling stats -----------------
def predict_fusion(models, history, adjust_strength=0.45, recent_n=20):
    if models is None or len(history) < 6:
        return None, None
    X, _ = create_features(history, window=6)
    if X.shape[0] == 0:
        return None, None
    latest = X[-1:].astype(float)
    # model probs
    try:
        prob_voting = models['voting'].predict_proba(latest)[0][1]
    except Exception:
        prob_voting = 0.5
    try:
        prob_stack = models['stacking'].predict_proba(latest)[0][1]
    except Exception:
        prob_stack = prob_voting
    model_prob = float(np.mean([prob_voting, prob_stack]))
    pattern_prob = pattern_detector(history)
    # rolling recent ratio
    n = min(len(history), recent_n)
    recent_ratio = sum(1 for x in history[-n:] if x == "T√†i") / n

    # combine: allow user-tunable adjust_strength (0..1)
    # stronger adjust_strength -> more weight to pattern/recent ratio
    adapt = adjust_strength
    final = (1 - adapt) * model_prob + adapt * (0.5 * pattern_prob + 0.5 * recent_ratio)

    # smoothing
    final = float(np.clip(0.9 * final + 0.1 * 0.5, 0.01, 0.99))
    preds = {
        "VotingProb": prob_voting,
        "StackingProb": prob_stack,
        "ModelAvg": model_prob,
        "PatternProb": pattern_prob,
        "RecentRatio": recent_ratio
    }
    return preds, final

# ----------------- Add / undo / import / export -----------------
def add_result(result):
    if result not in ("T√†i","X·ªâu"):
        return
    st.session_state.undo_stack.append((st.session_state.history.copy(), st.session_state.ai_conf.copy(), st.session_state.models))
    st.session_state.history.append(result)
    # clamp size
    if len(st.session_state.history) > 1000:
        st.session_state.history = st.session_state.history[-1000:]
        st.session_state.ai_conf = st.session_state.ai_conf[-1000:]
    # update ai_conf based on last pred
    if st.session_state.ai_last_pred is not None:
        was_correct = (st.session_state.ai_last_pred == result)
        st.session_state.ai_conf.append(1.15 if was_correct else 0.85)

def undo():
    if st.session_state.undo_stack:
        history, conf, models = st.session_state.undo_stack.pop()
        st.session_state.history = history
        st.session_state.ai_conf = conf
        st.session_state.models = models

def import_history_file(uploaded):
    if uploaded is None:
        return
    try:
        df = pd.read_csv(uploaded)
        if "K·∫øt qu·∫£" not in df.columns:
            st.error("CSV c·∫ßn c·ªôt 'K·∫øt qu·∫£'")
            return
        vals = df["K·∫øt qu·∫£"].tolist()
        if not all(v in ["T√†i","X·ªâu"] for v in vals):
            st.error("CSV ch·ª©a gi√° tr·ªã l·∫°. Ch·ªâ 'T√†i' ho·∫∑c 'X·ªâu' ƒë∆∞·ª£c ch·∫•p nh·∫≠n.")
            return
        st.session_state.undo_stack.append((st.session_state.history.copy(), st.session_state.ai_conf.copy(), st.session_state.models))
        st.session_state.history = vals
        st.session_state.ai_conf = [1.0]*len(vals)
        st.success("Import th√†nh c√¥ng.")
    except Exception as e:
        st.error(f"Import l·ªói: {e}")

# ----------------- Plot helpers -----------------
def plot_history_bar(history):
    if not history:
        return None
    df = pd.Series(history).value_counts(normalize=True) * 100
    fig, ax = plt.subplots()
    ax.bar(df.index, df.values)
    ax.set_ylim(0,100)
    ax.set_ylabel("T·ª∑ l·ªá (%)")
    ax.set_title("T·ª∑ l·ªá T√†i / X·ªâu")
    buf = io.BytesIO()
    fig.tight_layout()
    fig.savefig(buf, format="png", bbox_inches='tight')
    buf.seek(0)
    plt.close(fig)
    return buf

def plot_confidence_trend(conf_list):
    if not conf_list:
        return None
    fig, ax = plt.subplots(figsize=(6,2.5))
    ax.plot(conf_list[-100:], marker='o', linewidth=1)
    ax.set_title("Trend: ƒê·ªô tin c·∫≠y AI (l·∫ßn g·∫ßn nh·∫•t ‚Üí cu·ªëi)")
    ax.set_ylim(0,1)
    buf = io.BytesIO()
    fig.tight_layout()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    plt.close(fig)
    return buf

# ----------------- Load saved model/history if available -----------------
loaded = load_state_model(MODEL_PATH)
if loaded is not None and st.session_state.models is None:
    st.session_state.models = loaded

if os.path.exists(HISTORY_PATH) and not st.session_state.history:
    try:
        dfh = pd.read_csv(HISTORY_PATH)
        if "K·∫øt qu·∫£" in dfh.columns:
            st.session_state.history = dfh["K·∫øt qu·∫£"].tolist()
            st.session_state.ai_conf = [1.0]*len(st.session_state.history)
    except Exception:
        pass

# ----------------- UI Layout -----------------
sidebar = st.sidebar
sidebar.header("Controls")
with sidebar:
    adj_strength = st.slider("Adjust: Pattern vs Model (0=model only ‚Üí 1=pattern heavy)", 0.0, 1.0, 0.45, 0.05)
    recent_n = st.number_input("Recent window for rolling ratio (n)", min_value=5, max_value=100, value=20, step=5)
    use_xgb = st.checkbox("Allow XGBoost if available", value=False)
    save_model_on_train = st.checkbox("Save model to disk after training", value=True)
    show_conf_plot = st.checkbox("Show confidence trend", value=True)

# Top area
col1, col2, col3 = st.columns([2,1,1])
with col1:
    st.subheader("üìú L·ªãch s·ª≠ (g·∫ßn nh·∫•t)")
    if st.session_state.history:
        st.write(" ‚Üí ".join(st.session_state.history[-40:]))
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. Th√™m k·∫øt qu·∫£ ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
with col2:
    if st.button("‚ûï Th√™m T√†i"):
        add_result("T√†i")
        st.rerun()
    if st.button("‚ûñ Th√™m X·ªâu"):
        add_result("X·ªâu")
        st.rerun()
with col3:
    if st.button("‚Ü©Ô∏è Undo"):
        undo()
        st.success("ƒê√£ undo")
        st.rerun()

st.markdown("---")

# Left: charts & metrics; Right: training/prediction controls
left, right = st.columns([2,1])

with left:
    st.subheader("üìä Charts & Stats")
    buf = plot_history_bar(st.session_state.history)
    if buf:
        st.image(buf, use_column_width=True)
    if show_conf_plot:
        buf2 = plot_confidence_trend(st.session_state.ai_conf)
        if buf2:
            st.image(buf2, use_column_width=True)
    # rolling stats
    if st.session_state.history:
        n = min(len(st.session_state.history), recent_n)
        recent = st.session_state.history[-n:]
        rate_tai = recent.count("T√†i")/n
        st.write(f"üìà T·ª∑ l·ªá T√†i trong {n} v√°n g·∫ßn nh·∫•t: **{rate_tai:.1%}**")

with right:
    st.subheader("‚öôÔ∏è Hu·∫•n luy·ªán & D·ª± ƒëo√°n")
    st.write("Nh·∫•n **Hu·∫•n luy·ªán** ƒë·ªÉ train ensemble (ch·ªâ khi b·∫°n mu·ªën).")
    if st.button("üöÄ Hu·∫•n luy·ªán (Train)"):
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            models = train_fusion(tuple(st.session_state.history), tuple(st.session_state.ai_conf), use_xgb=use_xgb, cache_key=str(len(st.session_state.history)))
            if models is None:
                st.error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán (c·∫ßn >=12 entries v√† c·∫£ 2 class).")
            else:
                st.session_state.models = models
                if save_model_on_train:
                    saved = save_state_model(models, MODEL_PATH)
                    if saved:
                        st.success("Hu·∫•n luy·ªán xong v√† ƒë√£ l∆∞u model.")
                    else:
                        st.success("Hu·∫•n luy·ªán xong (kh√¥ng l∆∞u ƒë∆∞·ª£c model).")
                else:
                    st.success("Hu·∫•n luy·ªán xong (model ch∆∞a ƒë∆∞·ª£c l∆∞u).")
                # show quick metrics if available
                metrics = models.get("metrics", {})
                if metrics:
                    st.write("**Metrics (time-split):**")
                    st.json(metrics)
    st.write("---")
    # Prediction
    if st.button("ü§ñ D·ª± ƒëo√°n (Predict)"):
        if st.session_state.models is None:
            st.warning("Vui l√≤ng hu·∫•n luy·ªán model tr∆∞·ªõc.")
        else:
            preds, final = predict_fusion(st.session_state.models, st.session_state.history, adjust_strength=adj_strength, recent_n=recent_n)
            if preds:
                label = "T√†i" if final >= 0.5 else "X·ªâu"
                st.metric("üéØ D·ª± ƒëo√°n chung", f"{label} ({final*100:.2f}%)")
                st.write("Chi ti·∫øt:")
                st.write(f"- Voting prob: {preds['VotingProb']:.2%}")
                st.write(f"- Stacking prob: {preds['StackingProb']:.2%}")
                st.write(f"- Model average: {preds['ModelAvg']:.2%}")
                st.write(f"- Pattern prob: {preds['PatternProb']:.2%}")
                st.write(f"- Recent ratio (last {min(len(st.session_state.history), recent_n)}): {preds['RecentRatio']:.2%}")
                # store last pred/conf for ai_conf update when result entered
                st.session_state.ai_last_pred = label
                st.session_state.ai_conf.append(final)
            else:
                st.error("Kh√¥ng th·ªÉ d·ª± ƒëo√°n (ki·ªÉm tra l·ªãch s·ª≠ & model).")

    st.write("---")
    # Save/load history & model
    if st.button("üíæ L∆∞u l·ªãch s·ª≠ hi·ªán t·∫°i"):
        try:
            csvb = export_history_csv_bytes()
            with open(HISTORY_PATH, "wb") as f:
                f.write(csvb)
            st.success(f"ƒê√£ l∆∞u l·ªãch s·ª≠ v√†o {HISTORY_PATH}")
        except Exception as e:
            st.error(f"L∆∞u l·ªói: {e}")

    uploaded = st.file_uploader("üì§ Import l·ªãch s·ª≠ (CSV, c·ªôt 'K·∫øt qu·∫£')", type=["csv"])
    if uploaded:
        import_history_file(uploaded)
        st.rerun()

    st.download_button("üì• Export hi·ªán t·∫°i (CSV)", export_history_csv_bytes(), f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", "text/csv")

st.markdown("---")
st.caption("¬© Fusion Pro 2025 ‚Äî Hybrid + Improved. Ch·ªâ d√πng cho m·ª•c ƒë√≠ch h·ªçc thu·∫≠t.")
