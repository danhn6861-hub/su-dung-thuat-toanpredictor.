import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import TimeSeriesSplit
import matplotlib.pyplot as plt
import io
import base64
from datetime import datetime

st.set_page_config(page_title="AI D·ª± ƒëo√°n T√†i/X·ªâu N√¢ng Cao", layout="wide")

# Sidebar
st.sidebar.markdown("""
### ‚ö†Ô∏è L∆∞u √ù
·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh ch·∫•t gi·∫£i tr√≠ v√† tham kh·∫£o. Kh√¥ng khuy·∫øn kh√≠ch s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch c·ªù b·∫°c ho·∫∑c ƒë·∫ßu t∆∞ th·ª±c t·∫ø.
""")

# ====== Session state ======
if "history" not in st.session_state:
    st.session_state.history = []
if "ai_confidence" not in st.session_state:
    st.session_state.ai_confidence = []
if "models" not in st.session_state:
    st.session_state.models = None
if "ai_last_pred" not in st.session_state:
    st.session_state.ai_last_pred = None
if "undo_stack" not in st.session_state:
    st.session_state.undo_stack = []

# ====== H√†m t·∫°o ƒë·∫∑c tr∆∞ng ======
def create_features(history, window=6):
    if len(history) < window + 1:
        return np.empty((0, window)), np.empty((0,))
    X, y = [], []
    for i in range(window, len(history)):
        X.append([1 if x == "T√†i" else 0 for x in history[i-window:i]])
        y.append(1 if history[i] == "T√†i" else 0)
    return np.array(X), np.array(y)

# ====== Hu·∫•n luy·ªán ri√™ng t·ª´ng model ======
@st.cache_resource
def train_models_individual(history):
    X, y = create_features(history)
    if len(X) < 6:
        return None

    try:
        models = {
            'LogisticRegression': LogisticRegression(),
            'RandomForest': RandomForestClassifier(n_estimators=50, random_state=42),
            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric="logloss")
        }
        # Hu·∫•n luy·ªán t·ª´ng model
        for name, model in models.items():
            model.fit(X, y)
        
        # Stacking model
        estimators = [(n, m) for n, m in models.items()]
        stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
        stack.fit(X, y)
        models['Stacking'] = stack
        return models
    except Exception as e:
        st.error(f"L·ªói hu·∫•n luy·ªán: {str(e)}")
        return None

# ====== Pattern detector 6 v√°n ======
def pattern_detector(history, window=6):
    if len(history) < window * 2:
        return 0.5
    states = {'T√†i': 1, 'X·ªâu': 0}
    trans = np.zeros((2,2))
    for i in range(1,len(history)):
        prev = states[history[i-1]]
        curr = states[history[i]]
        trans[prev,curr] += 1
    trans /= np.sum(trans, axis=1, keepdims=True) + 1e-6
    last_state = states[history[-1]]
    return trans[last_state,1]

# ====== Pattern detector 10 v√°n g·∫ßn nh·∫•t v·ªõi tr·ªçng s·ªë ======
def pattern_detector_weighted(history, window=10):
    if len(history) < 3:  # √≠t nh·∫•t 3 v√°n
        return pattern_detector(history, window=6)
    actual_window = min(len(history), window)
    recent_history = history[-actual_window:]
    states = {'T√†i': 1, 'X·ªâu': 0}
    weights = np.linspace(1.5, 0.5, actual_window)  # tr·ªçng s·ªë gi·∫£m d·∫ßn
    weighted_sum = sum(weights[i] * states[recent_history[i]] for i in range(actual_window))
    return weighted_sum / sum(weights)

# ====== D·ª± ƒëo√°n ri√™ng t·ª´ng model + pattern ======
def predict_next(models, history):
    if len(history) < 6 or models is None:
        return None
    latest = np.array([[1 if x=="T√†i" else 0 for x in history[-6:]]])
    predictions = {}
    for name, model in models.items():
        if hasattr(model, "predict_proba"):
            prob = model.predict_proba(latest)[0][1]
        else:
            prob = float(model.predict(latest)[0])
        predictions[name] = prob
    predictions['Pattern Detector (6 v√°n)'] = pattern_detector(history)
    predictions['Pattern Detector (10 v√°n)'] = pattern_detector_weighted(history)
    # Final score t·ªïng h·ª£p
    final_score = (
        0.5 * predictions.get('Stacking',0.5) + 
        0.25 * predictions['Pattern Detector (6 v√°n)'] + 
        0.25 * predictions['Pattern Detector (10 v√°n)']
    )
    return predictions, final_score

# ====== Th√™m k·∫øt qu·∫£ + undo ======
def add_result(result):
    st.session_state.undo_stack.append(st.session_state.history.copy())
    st.session_state.history.append(result)
    if len(st.session_state.history) > 200:
        st.session_state.history = st.session_state.history[-200:]
def undo_last():
    if st.session_state.undo_stack:
        st.session_state.history = st.session_state.undo_stack.pop()

# ====== Export/Import ======
def export_history():
    df = pd.DataFrame({"K·∫øt qu·∫£": st.session_state.history})
    return df.to_csv(index=False).encode('utf-8')
def import_history(uploaded_file):
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.session_state.history = df["K·∫øt qu·∫£"].tolist()
        st.success("ƒê√£ import l·ªãch s·ª≠!")

# ====== V·∫Ω bi·ªÉu ƒë·ªì so s√°nh x√°c su·∫•t ======
def plot_prediction(preds):
    fig, ax = plt.subplots()
    names = list(preds.keys())
    values = [preds[n]*100 for n in names]
    ax.barh(names, values, color=['blue','orange','green','purple','red','brown'])
    ax.set_xlim(0,100)
    ax.set_xlabel("X√°c su·∫•t T√†i (%)")
    ax.set_title("D·ª± ƒëo√°n x√°c su·∫•t t·ª´ng model & pattern detector")
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    st.image(buf)

# ====== Giao di·ªán ======
st.title("üéØ AI D·ª± ƒëo√°n T√†i/X·ªâu ‚Äì ML + Pattern Detector")

col1,col2 = st.columns(2)
with col1:
    if st.button("Nh·∫≠p T√†i"):
        add_result("T√†i")
    if st.button("Nh·∫≠p X·ªâu"):
        add_result("X·ªâu")
with col2:
    if st.button("‚Ü©Ô∏è Undo"):
        undo_last()
    uploaded_file = st.file_uploader("Import CSV", type="csv")
    if uploaded_file:
        import_history(uploaded_file)
    csv = export_history()
    st.download_button("Export CSV", csv, f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")

st.divider()

if st.session_state.history:
    st.write("L·ªãch s·ª≠ g·∫ßn ƒë√¢y:", " ‚Üí ".join(st.session_state.history[-30:]))
    if st.button("‚öôÔ∏è Hu·∫•n luy·ªán model"):
        st.session_state.models = train_models_individual(st.session_state.history)
        st.success("ƒê√£ hu·∫•n luy·ªán xong!")

if st.session_state.models and len(st.session_state.history) >=6:
    preds, final_score = predict_next(st.session_state.models, st.session_state.history)
    st.subheader(f"üéØ D·ª± ƒëo√°n t·ªïng h·ª£p: {'T√†i' if final_score>=0.5 else 'X·ªâu'} ({final_score:.2%})")
    st.caption("D·ª± ƒëo√°n chi ti·∫øt t·ª´ng model + Pattern Detector")
    for k,v in preds.items():
        st.write(f"**{k}** ‚Üí {v:.2%} ({'T√†i' if v>=0.5 else 'X·ªâu'})")
    plot_prediction(preds)
