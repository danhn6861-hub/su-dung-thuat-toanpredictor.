import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import io
import base64
from datetime import datetime

st.set_page_config(page_title="Dá»± Ä‘oÃ¡n TÃ i/Xá»‰u AI - PhiÃªn báº£n NÃ¢ng Cao", layout="wide")

# Disclaimer
st.sidebar.markdown("""
### âš ï¸ LÆ°u Ã
á»¨ng dá»¥ng nÃ y chá»‰ mang tÃ­nh cháº¥t giáº£i trÃ­ vÃ  tham kháº£o. Káº¿t quáº£ dá»± Ä‘oÃ¡n dá»±a trÃªn lá»‹ch sá»­ ngáº«u nhiÃªn vÃ  khÃ´ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c. KhÃ´ng khuyáº¿n khÃ­ch sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch cá» báº¡c hoáº·c Ä‘áº§u tÆ° thá»±c táº¿, vÃ¬ cÃ¡c trÃ² chÆ¡i nhÆ° TÃ i/Xá»‰u thÆ°á»ng lÃ  ngáº«u nhiÃªn vÃ  cÃ³ thá»ƒ dáº«n Ä‘áº¿n rá»§i ro tÃ i chÃ­nh.
""")

# ====== Khá»Ÿi táº¡o tráº¡ng thÃ¡i ======
if "history" not in st.session_state:
    st.session_state.history = []
if "ai_confidence" not in st.session_state:
    st.session_state.ai_confidence = []
if "models" not in st.session_state:
    st.session_state.models = None
if "ai_last_pred" not in st.session_state:
    st.session_state.ai_last_pred = None
if "undo_stack" not in st.session_state:
    st.session_state.undo_stack = []
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

# ====== HÃ m táº¡o Ä‘áº·c trÆ°ng cáº£i tiáº¿n - giáº£m overfitting ======
def create_features_improved(history, window=5):
    if len(history) < window + 1:
        return np.empty((0, window + 2)), np.empty((0,))  # +2 cho features má»›i
    
    X = []
    y = []
    
    for i in range(window, len(history)):
        # Features cÆ¡ báº£n
        base_features = [1 if x == "TÃ i" else 0 for x in history[i - window:i]]
        
        # ThÃªm features thá»‘ng kÃª Ä‘á»ƒ giáº£m overfitting
        tai_count = sum(base_features)
        xiu_count = window - tai_count
        tai_ratio = tai_count / window
        
        # Features vá» biáº¿n Ä‘á»™ng (thay Ä‘á»•i liÃªn tá»¥c)
        changes = 0
        for j in range(1, len(base_features)):
            if base_features[j] != base_features[j-1]:
                changes += 1
        change_ratio = changes / (window - 1) if window > 1 else 0
        
        # Káº¿t há»£p táº¥t cáº£ features
        combined_features = base_features + [tai_ratio, change_ratio]
        
        X.append(combined_features)
        y.append(1 if history[i] == "TÃ i" else 0)
    
    return np.array(X), np.array(y)

# ====== Pattern detector cáº£i tiáº¿n ======
def pattern_detector_improved(history, lookback=8):
    if len(history) < 3:
        return 0.5
    
    # PhÃ¢n tÃ­ch Ä‘a chiá»u thay vÃ¬ chá»‰ transition Ä‘Æ¡n giáº£n
    recent = history[-lookback:] if len(history) >= lookback else history
    
    # TÃ­nh tá»· lá»‡ TÃ i/Xá»‰u gáº§n Ä‘Ã¢y
    tai_recent = sum(1 for x in recent if x == "TÃ i")
    xiu_recent = len(recent) - tai_recent
    
    # PhÃ¡t hiá»‡n chuá»—i
    max_streak = 0
    current_streak = 1
    for i in range(1, len(recent)):
        if recent[i] == recent[i-1]:
            current_streak += 1
            max_streak = max(max_streak, current_streak)
        else:
            current_streak = 1
    
    # Logic: náº¿u chuá»—i quÃ¡ dÃ i, kháº£ nÄƒng Ä‘áº£o chiá»u cao hÆ¡n
    streak_factor = min(max_streak / 4.0, 1.0)  # Chuá»—i 4+ lÃ  Ä‘Ã¡ng chÃº Ã½
    
    # CÃ¢n báº±ng hÆ¡n - trÃ¡nh thiÃªn vá»‹ sá»‘ Ä‘Ã´ng
    base_prob = tai_recent / len(recent)
    
    # Äiá»u chá»‰nh dá»±a trÃªn streak (mean reversion)
    if streak_factor > 0.5:
        adjusted_prob = 1.0 - base_prob  # ThiÃªn vá» Ä‘áº£o chiá»u khi streak dÃ i
    else:
        adjusted_prob = 0.5  # Trung láº­p khi khÃ´ng cÃ³ streak rÃµ rá»‡t
    
    return max(0.1, min(0.9, adjusted_prob))  # Giá»›i háº¡n trong khoáº£ng 10%-90%

# ====== Huáº¥n luyá»‡n mÃ´ hÃ¬nh cáº£i tiáº¿n - táº­p trung generalization ======
@st.cache_resource
def train_models_improved(history_tuple, ai_confidence_tuple, _cache_key):
    history = list(history_tuple)
    ai_confidence = list(ai_confidence_tuple)
    X, y = create_features_improved(history)
    
    if len(X) < 15:  # TÄƒng yÃªu cáº§u dá»¯ liá»‡u tá»‘i thiá»ƒu
        st.warning("Cáº§n Ã­t nháº¥t 15 vÃ¡n Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh á»•n Ä‘á»‹nh.")
        return None

    try:
        # Kiá»ƒm tra Ä‘a dáº¡ng dá»¯ liá»‡u
        unique_classes = len(np.unique(y))
        if unique_classes < 2:
            st.warning("Dá»¯ liá»‡u khÃ´ng Ä‘a dáº¡ng. Cáº§n cáº£ káº¿t quáº£ TÃ i vÃ  Xá»‰u.")
            return None

        # Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n hÆ¡n Ä‘á»ƒ giáº£m overfitting
        from sklearn.linear_model import LogisticRegressionCV
        
        # Cross-validation cho time series
        tscv = TimeSeriesSplit(n_splits=min(4, len(X)//5))
        
        # Model Ä‘Æ¡n giáº£n vá»›i regularization
        lr = LogisticRegressionCV(
            cv=tscv, 
            random_state=42,
            max_iter=1000,
            class_weight='balanced'  # CÃ¢n báº±ng class imbalance
        )
        
        # Random Forest vá»›i parameters giáº£m overfitting
        rf = RandomForestClassifier(
            n_estimators=30,  # Giáº£m sá»‘ cÃ¢y
            max_depth=5,      # Giá»›i háº¡n Ä‘á»™ sÃ¢u
            min_samples_split=10,
            random_state=42,
            class_weight='balanced'
        )
        
        # Huáº¥n luyá»‡n vá»›i sample_weight nháº¹ hÆ¡n
        recent_weight = np.linspace(0.3, 1.0, len(y))  # Giáº£m trá»ng sá»‘ gáº§n Ä‘Ã¢y
        combined_weight = recent_weight * np.array(ai_confidence[:len(y)]) if len(ai_confidence) >= len(y) else recent_weight
        
        # Huáº¥n luyá»‡n cÃ¡c model
        lr.fit(X, y, sample_weight=combined_weight)
        rf.fit(X, y, sample_weight=combined_weight)
        
        # Voting Ä‘Æ¡n giáº£n thay vÃ¬ stacking phá»©c táº¡p
        voting = VotingClassifier(
            estimators=[('lr', lr), ('rf', rf)],
            voting='soft'
        )
        voting.fit(X, y)
        
        # ÄÃ¡nh giÃ¡
        if len(X) > 20:
            # Chia train/test theo thá»i gian
            split_idx = int(0.8 * len(X))
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            voting.fit(X_train, y_train)
            acc = accuracy_score(y_test, voting.predict(X_test))
            st.info(f"Äá»™ chÃ­nh xÃ¡c kiá»ƒm tra: {acc:.2%}")
            
            # Kiá»ƒm tra overfitting
            train_acc = accuracy_score(y_train, voting.predict(X_train))
            if train_acc - acc > 0.3:  # ChÃªnh lá»‡ch lá»›n -> overfitting
                st.warning("MÃ´ hÃ¬nh cÃ³ thá»ƒ bá»‹ overfitting. Káº¿t quáº£ dá»± Ä‘oÃ¡n cáº§n tháº­n trá»ng.")
        
        return voting

    except Exception as e:
        st.error(f"Lá»—i huáº¥n luyá»‡n: {str(e)}")
        return None

# ====== HÃ m dá»± Ä‘oÃ¡n cáº£i tiáº¿n ======
def predict_next_improved(models, history):
    if len(history) < 5 or models is None:  # Giáº£m window requirement
        return None, None

    try:
        # Táº¡o features má»›i
        X, _ = create_features_improved(history)
        latest = X[-1:].reshape(1, -1) if len(X) > 0 else None
        
        if latest is None:
            return None, None
            
        model_prob = models.predict_proba(latest)[0][1]
        pattern_score = pattern_detector_improved(history)
        
        # Káº¿t há»£p cÃ¢n báº±ng hÆ¡n, Æ°u tiÃªn pattern khi cÃ³ streak rÃµ rá»‡t
        recent_tai_ratio = sum(1 for x in history[-5:] if x == "TÃ i") / 5
        if abs(recent_tai_ratio - 0.5) > 0.4:  # NghiÃªng háº³n 1 phÃ­a
            final_score = 0.4 * model_prob + 0.6 * pattern_score
        else:
            final_score = 0.6 * model_prob + 0.4 * pattern_score
            
        return {
            "Model Probability": model_prob, 
            "Pattern Analysis": pattern_score,
            "Recent Balance": recent_tai_ratio
        }, final_score
        
    except Exception as e:
        st.error(f"Lá»—i dá»± Ä‘oÃ¡n: {str(e)}")
        return None, None

# ====== HÃ m thÃªm káº¿t quáº£ vá»›i undo ======
def add_result(result):
    if st.session_state.is_processing:
        return
    if result not in ["TÃ i", "Xá»‰u"]:
        st.error(f"Káº¿t quáº£ khÃ´ng há»£p lá»‡: {result}")
        return
    st.session_state.is_processing = True
    try:
        st.session_state.undo_stack.append((st.session_state.history.copy(), st.session_state.ai_confidence.copy()))
        st.session_state.history.append(result)
        if len(st.session_state.history) > 200:
            st.session_state.history = st.session_state.history[-200:]
            st.session_state.ai_confidence = st.session_state.ai_confidence[-200:]
        if st.session_state.ai_last_pred is not None:
            was_correct = (st.session_state.ai_last_pred == result)
            st.session_state.ai_confidence.append(1.2 if was_correct else 0.8)
    finally:
        st.session_state.is_processing = False

# ====== HÃ m undo ======
def undo_last():
    if st.session_state.is_processing:
        return
    st.session_state.is_processing = True
    try:
        if st.session_state.undo_stack:
            history, confidence = st.session_state.undo_stack.pop()
            st.session_state.history = history
            st.session_state.ai_confidence = confidence
    finally:
        st.session_state.is_processing = False

# ====== Export/Import lá»‹ch sá»­ ======
def export_history():
    df = pd.DataFrame({"Káº¿t quáº£": st.session_state.history})
    csv = df.to_csv(index=False).encode('utf-8')
    return csv

def import_history(uploaded_file):
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            if "Káº¿t quáº£" not in df.columns:
                st.error("File CSV pháº£i cÃ³ cá»™t 'Káº¿t quáº£'.")
                return
            history = df["Káº¿t quáº£"].tolist()
            if not all(x in ["TÃ i", "Xá»‰u"] for x in history):
                st.error("Dá»¯ liá»‡u trong file CSV chá»©a giÃ¡ trá»‹ khÃ´ng há»£p lá»‡ (chá»‰ cháº¥p nháº­n 'TÃ i' hoáº·c 'Xá»‰u').")
                return
            st.session_state.history = history
            st.session_state.ai_confidence = [1.0] * len(history)
            st.session_state.undo_stack = []
            st.success("ÄÃ£ import lá»‹ch sá»­!")
        except Exception as e:
            st.error(f"Lá»—i khi import: {str(e)}")

# ====== Váº½ biá»ƒu Ä‘á»“ ======
def plot_history(history):
    if not history:
        return None
    df = pd.DataFrame({"Káº¿t quáº£": history})
    counts = df["Káº¿t quáº£"].value_counts(normalize=True) * 100
    fig, ax = plt.subplots()
    counts.plot(kind='bar', ax=ax, color=['green', 'red'])
    ax.set_ylabel("Tá»· lá»‡ (%)")
    ax.set_title("Tá»· lá»‡ TÃ i/Xá»‰u trong lá»‹ch sá»­")
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return base64.b64encode(buf.read()).decode('utf-8')

# ====== Giao diá»‡n ======
st.title("ğŸ¯ AI Dá»± Ä‘oÃ¡n TÃ i / Xá»‰u â€“ PhiÃªn báº£n NÃ¢ng Cao Tá»± Há»c")

col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.markdown("#### ğŸ“Š Káº¿t quáº£ gáº§n Ä‘Ã¢y:")
    if st.session_state.history:
        st.write(" â†’ ".join(st.session_state.history[-30:]))
    else:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u, nháº­p káº¿t quáº£ Ä‘á»ƒ báº¯t Ä‘áº§u.")

with col2:
    if st.button("ğŸ§¹ XÃ³a lá»‹ch sá»­", key="clear_history"):
        confirm_clear = st.checkbox("XÃ¡c nháº­n xÃ³a toÃ n bá»™ lá»‹ch sá»­?", key="confirm_clear")
        if confirm_clear:
            st.session_state.history = []
            st.session_state.ai_confidence = []
            st.session_state.undo_stack = []
            st.session_state.models = None
            st.success("ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­!")
            st.rerun()

with col3:
    if st.button("â†©ï¸ Undo nháº­p cuá»‘i", key="undo_last"):
        undo_last()
        st.success("ÄÃ£ undo nháº­p cuá»‘i!")
        st.rerun()

# Biá»ƒu Ä‘á»“
if st.session_state.history:
    try:
        img_data = plot_history(st.session_state.history)
        if img_data:
            st.image(f"data:image/png;base64,{img_data}", caption="Biá»ƒu Ä‘á»“ tá»· lá»‡ TÃ i/Xá»‰u", use_container_width=True)
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ váº½ biá»ƒu Ä‘á»“: {str(e)}. Vui lÃ²ng kiá»ƒm tra thÆ° viá»‡n matplotlib.")

st.divider()

# NÃºt nháº­p káº¿t quáº£ vá»›i key unique
col_tai, col_xiu = st.columns(2)
with col_tai:
    if st.button("Nháº­p TÃ i", key="add_tai", disabled=st.session_state.is_processing):
        add_result("TÃ i")
        st.success("ÄÃ£ thÃªm TÃ i!")
        st.rerun()
with col_xiu:
    if st.button("Nháº­p Xá»‰u", key="add_xiu", disabled=st.session_state.is_processing):
        add_result("Xá»‰u")
        st.success("ÄÃ£ thÃªm Xá»‰u!")
        st.rerun()

st.divider()

# Huáº¥n luyá»‡n
if st.button("âš™ï¸ Huáº¥n luyá»‡n láº¡i tá»« lá»‹ch sá»­", key="train_models"):
    with st.spinner("Äang huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh cáº£i tiáº¿n..."):
        cache_key = str(len(st.session_state.history)) + str(st.session_state.history[-10:])
        st.session_state.models = train_models_improved(tuple(st.session_state.history), tuple(st.session_state.ai_confidence), cache_key)
    if st.session_state.models is not None:
        st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng vá»›i phiÃªn báº£n cáº£i tiáº¿n!")

# Dá»± Ä‘oÃ¡n
if len(st.session_state.history) >= 5:
    if st.session_state.models is None:
        st.info("Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
    else:
        preds, final_score = predict_next_improved(st.session_state.models, st.session_state.history)
        if preds:
            st.session_state.ai_last_pred = "TÃ i" if final_score >= 0.5 else "Xá»‰u"
            st.subheader(f"ğŸ¯ Dá»± Ä‘oÃ¡n chung: **{st.session_state.ai_last_pred}** ({final_score:.2%})")
            st.caption("Tá»•ng há»£p tá»« Model + Pattern Analysis (phiÃªn báº£n cáº£i tiáº¿n):")
            for k, v in preds.items():
                if k == "Recent Balance":
                    st.write(f"**{k}** â†’ {v:.2%} TÃ i trong 5 vÃ¡n gáº§n nháº¥t")
                else:
                    st.write(f"**{k}** â†’ {v:.2%}")
            
            # ThÃªm phÃ¢n tÃ­ch streak
            recent = st.session_state.history[-5:]
            current_streak = 1
            for i in range(1, len(recent)):
                if recent[i] == recent[i-1]:
                    current_streak += 1
                else:
                    break
            if current_streak >= 3:
                st.info(f"ğŸ” Äang cÃ³ chuá»—i {recent[0]} {current_streak} vÃ¡n liÃªn tiáº¿p - Pattern detector Ä‘ang xem xÃ©t kháº£ nÄƒng Ä‘áº£o chiá»u")
else:
    st.warning("Cáº§n Ã­t nháº¥t 5 vÃ¡n Ä‘á»ƒ báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n.")

st.divider()

# Export/Import
col_export, col_import = st.columns(2)
with col_export:
    csv = export_history()
    st.download_button("ğŸ“¥ Export lá»‹ch sá»­ (CSV)", csv, f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", "text/csv", key="export_history")
with col_import:
    uploaded_file = st.file_uploader("ğŸ“¤ Import lá»‹ch sá»­ tá»« CSV", type="csv", key="import_file")
    if uploaded_file:
        import_history(uploaded_file)

# ThÃ´ng tin vá» cáº£i tiáº¿n
st.sidebar.markdown("""
### ğŸš€ PhiÃªn báº£n Cáº£i Tiáº¿n
**Chá»‘ng Overfitting:**
- Features thá»‘ng kÃª Ä‘a dáº¡ng
- Regularization máº¡nh
- Model Ä‘Æ¡n giáº£n hÆ¡n
- Time-series validation

**Pattern Detection ThÃ´ng Minh:**
- PhÃ¡t hiá»‡n chuá»—i dÃ i
- Mean reversion logic
- CÃ¢n báº±ng tá»· lá»‡ lá»‹ch sá»­
""")
