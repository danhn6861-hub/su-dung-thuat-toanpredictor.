import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import io
import base64
from datetime import datetime

st.set_page_config(page_title="Dá»± Ä‘oÃ¡n TÃ i/Xá»‰u AI - PhiÃªn báº£n NÃ¢ng Cao", layout="wide")

# Disclaimer
st.sidebar.markdown("""
### âš ï¸ LÆ°u Ã
á»¨ng dá»¥ng nÃ y chá»‰ mang tÃ­nh cháº¥t giáº£i trÃ­ vÃ  tham kháº£o. Káº¿t quáº£ dá»± Ä‘oÃ¡n dá»±a trÃªn lá»‹ch sá»­ ngáº«u nhiÃªn vÃ  khÃ´ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c. KhÃ´ng khuyáº¿n khÃ­ch sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch cá» báº¡c hoáº·c Ä‘áº§u tÆ° thá»±c táº¿, vÃ¬ cÃ¡c trÃ² chÆ¡i nhÆ° TÃ i/Xá»‰u thÆ°á»ng lÃ  ngáº«u nhiÃªn vÃ  cÃ³ thá»ƒ dáº«n Ä‘áº¿n rá»§i ro tÃ i chÃ­nh.
""")

# ====== Khá»Ÿi táº¡o tráº¡ng thÃ¡i ======
if "history" not in st.session_state:
    st.session_state.history = []
if "ai_confidence" not in st.session_state:
    st.session_state.ai_confidence = []
if "models" not in st.session_state:
    st.session_state.models = None
if "ai_last_pred" not in st.session_state:
    st.session_state.ai_last_pred = None
if "undo_stack" not in st.session_state:
    st.session_state.undo_stack = []
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

# ====== HÃ m táº¡o Ä‘áº·c trÆ°ng ======
def create_features(history, window=6):
    if len(history) < window + 1:
        return np.empty((0, window)), np.empty((0,))
    X = []
    y = []
    for i in range(window, len(history)):
        X.append([1 if x == "TÃ i" else 0 for x in history[i - window:i]])
        y.append(1 if history[i] == "TÃ i" else 0)
    return np.array(X), np.array(y)

# ====== Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh vá»›i cáº£i thiá»‡n ======
@st.cache_resource
def train_models(history_tuple, ai_confidence_tuple, _cache_key):
    history = list(history_tuple)
    ai_confidence = list(ai_confidence_tuple)
    X, y = create_features(history)
    if len(X) < 10:
        st.warning("Cáº§n Ã­t nháº¥t 10 vÃ¡n Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.")
        return None

    try:
        # Kiá»ƒm tra dá»¯ liá»‡u cÃ¢n báº±ng
        if np.all(y == 0) or np.all(y == 1):
            st.warning("Dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng (toÃ n TÃ i hoáº·c Xá»‰u). MÃ´ hÃ¬nh cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c.")
            return None

        # Sá»­ dá»¥ng KFold vá»›i shuffle=False Ä‘á»ƒ phÃ¹ há»£p time-series vÃ  lÃ  partitioner
        n_splits = min(3, len(X) // 4)  # Má»—i split cáº§n Ã­t nháº¥t 4 máº«u
        if n_splits < 2:
            # Fallback: Stacking mÃ  khÃ´ng cross-validation náº¿u khÃ´ng Ä‘á»§ dá»¯ liá»‡u cho CV
            st.warning("Dá»¯ liá»‡u quÃ¡ Ã­t Ä‘á»ƒ cross-validation, huáº¥n luyá»‡n stacking trá»±c tiáº¿p...")
            recent_weight = np.linspace(0.5, 1.0, len(y))
            combined_weight = recent_weight * np.array(ai_confidence[:len(y)]) if len(ai_confidence) >= len(y) else recent_weight

            lr = LogisticRegression().fit(X, y, sample_weight=combined_weight)
            rf = RandomForestClassifier(n_estimators=50, random_state=42).fit(X, y, sample_weight=combined_weight)
            xgb = XGBClassifier(use_label_encoder=False, eval_metric="logloss").fit(X, y, sample_weight=combined_weight)

            estimators = [
                ('lr', lr),
                ('rf', rf),
                ('xgb', xgb)
            ]

            stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=None)
            stack.fit(X, y)
            return stack

        tscv = KFold(n_splits=n_splits, shuffle=False)

        # AI Strategy â€“ há»c trá»ng sá»‘ theo thá»i gian vÃ  Ä‘á»™ tin cáº­y
        recent_weight = np.linspace(0.5, 1.0, len(y))
        combined_weight = recent_weight * np.array(ai_confidence[:len(y)]) if len(ai_confidence) >= len(y) else recent_weight

        # Huáº¥n luyá»‡n base models vá»›i sample_weight
        lr = LogisticRegression().fit(X, y, sample_weight=combined_weight)
        rf = RandomForestClassifier(n_estimators=50, random_state=42).fit(X, y, sample_weight=combined_weight)
        xgb = XGBClassifier(use_label_encoder=False, eval_metric="logloss").fit(X, y, sample_weight=combined_weight)

        # CÃ¡c base models
        estimators = [
            ('lr', lr),
            ('rf', rf),
            ('xgb', xgb)
        ]

        # Stacking classifier
        stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=tscv)
        stack.fit(X, y)

        # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
        if len(X) > 20:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
            acc = accuracy_score(y_test, stack.predict(X_test))
            st.info(f"Äá»™ chÃ­nh xÃ¡c Ä‘Ã¡nh giÃ¡ (test set): {acc:.2%}")

        return stack

    except Exception as e:
        st.error(f"Lá»—i huáº¥n luyá»‡n: {str(e)}. Vui lÃ²ng thá»­ nháº­p thÃªm dá»¯ liá»‡u hoáº·c kiá»ƒm tra láº¡i.")
        return None

# ====== HÃ m phÃ¡t hiá»‡n pattern cáº£i thiá»‡n (sá»­ dá»¥ng Markov chain Ä‘Æ¡n giáº£n) ======
def pattern_detector(history, window=6):
    if len(history) < 2:
        return 0.5

    states = {'TÃ i': 1, 'Xá»‰u': 0}
    trans = np.zeros((2, 2))
    for i in range(1, len(history)):
        prev = states[history[i-1]]
        curr = states[history[i]]
        trans[prev, curr] += 1

    row_sums = np.sum(trans, axis=1, keepdims=True)
    trans = np.divide(trans, row_sums, where=row_sums != 0)

    last_state = states[history[-1]]
    return trans[last_state, 1]

# ====== HÃ m dá»± Ä‘oÃ¡n ======
def predict_next(models, history):
    if len(history) < 6 or models is None:
        return None, None

    try:
        latest = np.array([[1 if x == "TÃ i" else 0 for x in history[-6:]]])
        stack_prob = models.predict_proba(latest)[0][1]
        pattern_score = pattern_detector(history)
        final_score = 0.7 * stack_prob + 0.3 * pattern_score
        return {"Stacking Model": stack_prob, "Pattern Detector": pattern_score}, final_score
    except Exception as e:
        st.error(f"Lá»—i dá»± Ä‘oÃ¡n: {str(e)}")
        return None, None

# ====== HÃ m thÃªm káº¿t quáº£ vá»›i undo ======
def add_result(result):
    if st.session_state.is_processing:
        return
    if result not in ["TÃ i", "Xá»‰u"]:
        st.error(f"Káº¿t quáº£ khÃ´ng há»£p lá»‡: {result}")
        return
    st.session_state.is_processing = True
    try:
        st.session_state.undo_stack.append((st.session_state.history.copy(), st.session_state.ai_confidence.copy()))
        st.session_state.history.append(result)
        if len(st.session_state.history) > 200:
            st.session_state.history = st.session_state.history[-200:]
            st.session_state.ai_confidence = st.session_state.ai_confidence[-200:]
        if st.session_state.ai_last_pred is not None:
            was_correct = (st.session_state.ai_last_pred == result)
            st.session_state.ai_confidence.append(1.2 if was_correct else 0.8)
    finally:
        st.session_state.is_processing = False

# ====== HÃ m undo ======
def undo_last():
    if st.session_state.is_processing:
        return
    st.session_state.is_processing = True
    try:
        if st.session_state.undo_stack:
            history, confidence = st.session_state.undo_stack.pop()
            st.session_state.history = history
            st.session_state.ai_confidence = confidence
    finally:
        st.session_state.is_processing = False

# ====== Export/Import lá»‹ch sá»­ ======
def export_history():
    df = pd.DataFrame({"Káº¿t quáº£": st.session_state.history})
    csv = df.to_csv(index=False).encode('utf-8')
    return csv

def import_history(uploaded_file):
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            if "Káº¿t quáº£" not in df.columns:
                st.error("File CSV pháº£i cÃ³ cá»™t 'Káº¿t quáº£'.")
                return
            history = df["Káº¿t quáº£"].tolist()
            if not all(x in ["TÃ i", "Xá»‰u"] for x in history):
                st.error("Dá»¯ liá»‡u trong file CSV chá»©a giÃ¡ trá»‹ khÃ´ng há»£p lá»‡ (chá»‰ cháº¥p nháº­n 'TÃ i' hoáº·c 'Xá»‰u').")
                return
            st.session_state.history = history
            st.session_state.ai_confidence = [1.0] * len(history)
            st.session_state.undo_stack = []
            st.success("ÄÃ£ import lá»‹ch sá»­!")
        except Exception as e:
            st.error(f"Lá»—i khi import: {str(e)}")

# ====== Váº½ biá»ƒu Ä‘á»“ ======
def plot_history(history):
    if not history:
        return None
    df = pd.DataFrame({"Káº¿t quáº£": history})
    counts = df["Káº¿t quáº£"].value_counts(normalize=True) * 100
    fig, ax = plt.subplots()
    counts.plot(kind='bar', ax=ax, color=['green', 'red'])
    ax.set_ylabel("Tá»· lá»‡ (%)")
    ax.set_title("Tá»· lá»‡ TÃ i/Xá»‰u trong lá»‹ch sá»­")
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return base64.b64encode(buf.read()).decode('utf-8')

# ====== Giao diá»‡n ======
st.title("ğŸ¯ AI Dá»± Ä‘oÃ¡n TÃ i / Xá»‰u â€“ PhiÃªn báº£n NÃ¢ng Cao Tá»± Há»c")

col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.markdown("#### ğŸ“Š Káº¿t quáº£ gáº§n Ä‘Ã¢y:")
    if st.session_state.history:
        st.write(" â†’ ".join(st.session_state.history[-30:]))
    else:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u, nháº­p káº¿t quáº£ Ä‘á»ƒ báº¯t Ä‘áº§u.")

with col2:
    if st.button("ğŸ§¹ XÃ³a lá»‹ch sá»­", key="clear_history"):
        confirm_clear = st.checkbox("XÃ¡c nháº­n xÃ³a toÃ n bá»™ lá»‹ch sá»­?", key="confirm_clear")
        if confirm_clear:
            st.session_state.history = []
            st.session_state.ai_confidence = []
            st.session_state.undo_stack = []
            st.session_state.models = None
            st.success("ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­!")
            st.rerun()

with col3:
    if st.button("â†©ï¸ Undo nháº­p cuá»‘i", key="undo_last"):
        undo_last()
        st.success("ÄÃ£ undo nháº­p cuá»‘i!")
        st.rerun()

# Biá»ƒu Ä‘á»“
if st.session_state.history:
    try:
        img_data = plot_history(st.session_state.history)
        if img_data:
            st.image(f"data:image/png;base64,{img_data}", caption="Biá»ƒu Ä‘á»“ tá»· lá»‡ TÃ i/Xá»‰u", use_container_width=True)
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ váº½ biá»ƒu Ä‘á»“: {str(e)}. Vui lÃ²ng kiá»ƒm tra thÆ° viá»‡n matplotlib.")

st.divider()

# NÃºt nháº­p káº¿t quáº£ vá»›i key unique
col_tai, col_xiu = st.columns(2)
with col_tai:
    if st.button("Nháº­p TÃ i", key="add_tai", disabled=st.session_state.is_processing):
        add_result("TÃ i")
        st.success("ÄÃ£ thÃªm TÃ i!")
        st.rerun()
with col_xiu:
    if st.button("Nháº­p Xá»‰u", key="add_xiu", disabled=st.session_state.is_processing):
        add_result("Xá»‰u")
        st.success("ÄÃ£ thÃªm Xá»‰u!")
        st.rerun()

st.divider()

# Huáº¥n luyá»‡n
if st.button("âš™ï¸ Huáº¥n luyá»‡n láº¡i tá»« lá»‹ch sá»­", key="train_models"):
    with st.spinner("Äang huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh..."):
        cache_key = str(len(st.session_state.history)) + str(st.session_state.history[-10:])
        st.session_state.models = train_models(tuple(st.session_state.history), tuple(st.session_state.ai_confidence), cache_key)
    if st.session_state.models is not None:
        st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng!")

# Dá»± Ä‘oÃ¡n
if len(st.session_state.history) >= 6:
    if st.session_state.models is None:
        st.info("Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
    else:
        preds, final_score = predict_next(st.session_state.models, st.session_state.history)
        if preds:
            st.session_state.ai_last_pred = "TÃ i" if final_score >= 0.5 else "Xá»‰u"
            st.subheader(f"ğŸ¯ Dá»± Ä‘oÃ¡n chung: **{st.session_state.ai_last_pred}** ({final_score:.2%})")
            st.caption("Tá»•ng há»£p tá»« Stacking Model + Pattern Detector:")
            for k, v in preds.items():
                st.write(f"**{k}** â†’ {v:.2%}")
else:
    st.warning("Cáº§n Ã­t nháº¥t 6 vÃ¡n Ä‘á»ƒ báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n.")

st.divider()

# Export/Import
col_export, col_import = st.columns(2)
with col_export:
    csv = export_history()
    st.download_button("ğŸ“¥ Export lá»‹ch sá»­ (CSV)", csv, f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", "text/csv", key="export_history")
with col_import:
    uploaded_file = st.file_uploader("ğŸ“¤ Import lá»‹ch sá»­ tá»« CSV", type="csv", key="import_file")
    if uploaded_file:
        import_history(uploaded_file)
