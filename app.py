import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import io
import base64
from datetime import datetime

st.set_page_config(page_title="D·ª± ƒëo√°n T√†i/X·ªâu AI - Phi√™n b·∫£n N√¢ng Cao", layout="wide")

# Disclaimer
st.sidebar.markdown("""
### ‚ö†Ô∏è L∆∞u √ù
·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh ch·∫•t gi·∫£i tr√≠ v√† tham kh·∫£o. K·∫øt qu·∫£ d·ª± ƒëo√°n d·ª±a tr√™n l·ªãch s·ª≠ ng·∫´u nhi√™n v√† kh√¥ng ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c. Kh√¥ng khuy·∫øn kh√≠ch s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch c·ªù b·∫°c ho·∫∑c ƒë·∫ßu t∆∞ th·ª±c t·∫ø, v√¨ c√°c tr√≤ ch∆°i nh∆∞ T√†i/X·ªâu th∆∞·ªùng l√† ng·∫´u nhi√™n v√† c√≥ th·ªÉ d·∫´n ƒë·∫øn r·ªßi ro t√†i ch√≠nh.
""")

# ====== Kh·ªüi t·∫°o tr·∫°ng th√°i ======
if "history" not in st.session_state:
    st.session_state.history = []
if "ai_confidence" not in st.session_state:
    st.session_state.ai_confidence = []
if "models" not in st.session_state:
    st.session_state.models = None
if "ai_last_pred" not in st.session_state:
    st.session_state.ai_last_pred = None
if "undo_stack" not in st.session_state:
    st.session_state.undo_stack = []
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

# ====== H√†m t·∫°o ƒë·∫∑c tr∆∞ng ======
def create_features(history, window=6):
    if len(history) < window + 1:
        return np.empty((0, window)), np.empty((0,))
    X = []
    y = []
    for i in range(window, len(history)):
        X.append([1 if x == "T√†i" else 0 for x in history[i - window:i]])
        y.append(1 if history[i] == "T√†i" else 0)
    return np.array(X), np.array(y)

# ====== Hu·∫•n luy·ªán c√°c m√¥ h√¨nh v·ªõi c·∫£i thi·ªán ======
@st.cache_resource
def train_models(history_tuple, ai_confidence_tuple, _cache_key):
    history = list(history_tuple)
    ai_confidence = list(ai_confidence_tuple)
    X, y = create_features(history)
    if len(X) < 10:
        st.warning("C·∫ßn √≠t nh·∫•t 10 v√°n ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
        return None

    try:
        # Ki·ªÉm tra d·ªØ li·ªáu c√¢n b·∫±ng
        if np.all(y == 0) or np.all(y == 1):
            st.warning("D·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng (to√†n T√†i ho·∫∑c X·ªâu). M√¥ h√¨nh c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c.")
            return None

        # S·ª≠ d·ª•ng KFold v·ªõi shuffle=False ƒë·ªÉ ph√π h·ª£p time-series v√† l√† partitioner
        n_splits = min(3, len(X) // 4)  # M·ªói split c·∫ßn √≠t nh·∫•t 4 m·∫´u
        if n_splits < 2:
            # Fallback: Stacking m√† kh√¥ng cross-validation n·∫øu kh√¥ng ƒë·ªß d·ªØ li·ªáu cho CV
            st.warning("D·ªØ li·ªáu qu√° √≠t ƒë·ªÉ cross-validation, hu·∫•n luy·ªán stacking tr·ª±c ti·∫øp...")
            recent_weight = np.linspace(0.5, 1.0, len(y))
            combined_weight = recent_weight * np.array(ai_confidence[:len(y)]) if len(ai_confidence) >= len(y) else recent_weight

            lr = LogisticRegression().fit(X, y, sample_weight=combined_weight)
            rf = RandomForestClassifier(n_estimators=50, random_state=42).fit(X, y, sample_weight=combined_weight)
            xgb = XGBClassifier(use_label_encoder=False, eval_metric="logloss").fit(X, y, sample_weight=combined_weight)

            estimators = [
                ('lr', lr),
                ('rf', rf),
                ('xgb', xgb)
            ]

            stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=None)
            stack.fit(X, y)
            return stack

        tscv = KFold(n_splits=n_splits, shuffle=False)

        # AI Strategy ‚Äì h·ªçc tr·ªçng s·ªë theo th·ªùi gian v√† ƒë·ªô tin c·∫≠y
        recent_weight = np.linspace(0.5, 1.0, len(y))
        combined_weight = recent_weight * np.array(ai_confidence[:len(y)]) if len(ai_confidence) >= len(y) else recent_weight

        # Hu·∫•n luy·ªán base models v·ªõi sample_weight
        lr = LogisticRegression().fit(X, y, sample_weight=combined_weight)
        rf = RandomForestClassifier(n_estimators=50, random_state=42).fit(X, y, sample_weight=combined_weight)
        xgb = XGBClassifier(use_label_encoder=False, eval_metric="logloss").fit(X, y, sample_weight=combined_weight)

        # C√°c base models
        estimators = [
            ('lr', lr),
            ('rf', rf),
            ('xgb', xgb)
        ]

        # Stacking classifier
        stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=tscv)
        stack.fit(X, y)

        # ƒê√°nh gi√° m√¥ h√¨nh
        if len(X) > 20:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
            acc = accuracy_score(y_test, stack.predict(X_test))
            st.info(f"ƒê·ªô ch√≠nh x√°c ƒë√°nh gi√° (test set): {acc:.2%}")

        return stack

    except Exception as e:
        st.error(f"L·ªói hu·∫•n luy·ªán: {str(e)}. Vui l√≤ng th·ª≠ nh·∫≠p th√™m d·ªØ li·ªáu ho·∫∑c ki·ªÉm tra l·∫°i.")
        return None

# ====== H√†m ph√°t hi·ªán pattern c·∫£i thi·ªán (s·ª≠ d·ª•ng Markov chain ƒë∆°n gi·∫£n) ======
def pattern_detector(history, window=6):
    if len(history) < 2:
        return 0.5

    states = {'T√†i': 1, 'X·ªâu': 0}
    trans = np.zeros((2, 2))
    for i in range(1, len(history)):
        prev = states[history[i-1]]
        curr = states[history[i]]
        trans[prev, curr] += 1

    row_sums = np.sum(trans, axis=1, keepdims=True)
    trans = np.divide(trans, row_sums, where=row_sums != 0)

    last_state = states[history[-1]]
    return trans[last_state, 1]

# ====== H√†m d·ª± ƒëo√°n ======
def predict_next(models, history):
    if len(history) < 6 or models is None:
        return None, None

    try:
        latest = np.array([[1 if x == "T√†i" else 0 for x in history[-6:]]])
        stack_prob = models.predict_proba(latest)[0][1]
        pattern_score = pattern_detector(history)
        final_score = 0.7 * stack_prob + 0.3 * pattern_score
        return {"Stacking Model": stack_prob, "Pattern Detector": pattern_score}, final_score
    except Exception as e:
        st.error(f"L·ªói d·ª± ƒëo√°n: {str(e)}")
        return None, None

# ====== H√†m th√™m k·∫øt qu·∫£ v·ªõi undo ======
def add_result(result):
    if st.session_state.is_processing:
        return
    if result not in ["T√†i", "X·ªâu"]:
        st.error(f"K·∫øt qu·∫£ kh√¥ng h·ª£p l·ªá: {result}")
        return
    st.session_state.is_processing = True
    try:
        st.session_state.undo_stack.append((st.session_state.history.copy(), st.session_state.ai_confidence.copy()))
        st.session_state.history.append(result)
        if len(st.session_state.history) > 200:
            st.session_state.history = st.session_state.history[-200:]
            st.session_state.ai_confidence = st.session_state.ai_confidence[-200:]
        if st.session_state.ai_last_pred is not None:
            was_correct = (st.session_state.ai_last_pred == result)
            st.session_state.ai_confidence.append(1.2 if was_correct else 0.8)
    finally:
        st.session_state.is_processing = False

# ====== H√†m undo ======
def undo_last():
    if st.session_state.is_processing:
        return
    st.session_state.is_processing = True
    try:
        if st.session_state.undo_stack:
            history, confidence = st.session_state.undo_stack.pop()
            st.session_state.history = history
            st.session_state.ai_confidence = confidence
    finally:
        st.session_state.is_processing = False

# ====== Export/Import l·ªãch s·ª≠ ======
def export_history():
    df = pd.DataFrame({"K·∫øt qu·∫£": st.session_state.history})
    csv = df.to_csv(index=False).encode('utf-8')
    return csv

def import_history(uploaded_file):
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            if "K·∫øt qu·∫£" not in df.columns:
                st.error("File CSV ph·∫£i c√≥ c·ªôt 'K·∫øt qu·∫£'.")
                return
            history = df["K·∫øt qu·∫£"].tolist()
            if not all(x in ["T√†i", "X·ªâu"] for x in history):
                st.error("D·ªØ li·ªáu trong file CSV ch·ª©a gi√° tr·ªã kh√¥ng h·ª£p l·ªá (ch·ªâ ch·∫•p nh·∫≠n 'T√†i' ho·∫∑c 'X·ªâu').")
                return
            st.session_state.history = history
            st.session_state.ai_confidence = [1.0] * len(history)
            st.session_state.undo_stack = []
            st.success("ƒê√£ import l·ªãch s·ª≠!")
        except Exception as e:
            st.error(f"L·ªói khi import: {str(e)}")

# ====== V·∫Ω bi·ªÉu ƒë·ªì ======
def plot_history(history):
    if not history:
        return None
    df = pd.DataFrame({"K·∫øt qu·∫£": history})
    counts = df["K·∫øt qu·∫£"].value_counts(normalize=True) * 100
    fig, ax = plt.subplots()
    counts.plot(kind='bar', ax=ax, color=['green', 'red'])
    ax.set_ylabel("T·ª∑ l·ªá (%)")
    ax.set_title("T·ª∑ l·ªá T√†i/X·ªâu trong l·ªãch s·ª≠")
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return base64.b64encode(buf.read()).decode('utf-8')

# ====== Giao di·ªán ======
st.title("üéØ AI D·ª± ƒëo√°n T√†i / X·ªâu ‚Äì Phi√™n b·∫£n N√¢ng Cao T·ª± H·ªçc")

col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.markdown("#### üìä K·∫øt qu·∫£ g·∫ßn ƒë√¢y:")
    if st.session_state.history:
        st.write(" ‚Üí ".join(st.session_state.history[-30:]))
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu, nh·∫≠p k·∫øt qu·∫£ ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

with col2:
    if st.button("üßπ X√≥a l·ªãch s·ª≠", key="clear_history"):
        confirm_clear = st.checkbox("X√°c nh·∫≠n x√≥a to√†n b·ªô l·ªãch s·ª≠?", key="confirm_clear")
        if confirm_clear:
            st.session_state.history = []
            st.session_state.ai_confidence = []
            st.session_state.undo_stack = []
            st.session_state.models = None
            st.success("ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠!")
            st.rerun()

with col3:
    if st.button("‚Ü©Ô∏è Undo nh·∫≠p cu·ªëi", key="undo_last"):
        undo_last()
        st.success("ƒê√£ undo nh·∫≠p cu·ªëi!")
        st.rerun()

# Bi·ªÉu ƒë·ªì
if st.session_state.history:
    try:
        img_data = plot_history(st.session_state.history)
        if img_data:
            st.image(f"data:image/png;base64,{img_data}", caption="Bi·ªÉu ƒë·ªì t·ª∑ l·ªá T√†i/X·ªâu", use_container_width=True)
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì: {str(e)}. Vui l√≤ng ki·ªÉm tra th∆∞ vi·ªán matplotlib.")

st.divider()

# N√∫t nh·∫≠p k·∫øt qu·∫£ v·ªõi key unique
col_tai, col_xiu = st.columns(2)
with col_tai:
    if st.button("Nh·∫≠p T√†i", key="add_tai", disabled=st.session_state.is_processing):
        add_result("T√†i")
        st.success("ƒê√£ th√™m T√†i!")
        st.rerun()
with col_xiu:
    if st.button("Nh·∫≠p X·ªâu", key="add_xiu", disabled=st.session_state.is_processing):
        add_result("X·ªâu")
        st.success("ƒê√£ th√™m X·ªâu!")
        st.rerun()

st.divider()

# Hu·∫•n luy·ªán
if st.button("‚öôÔ∏è Hu·∫•n luy·ªán l·∫°i t·ª´ l·ªãch s·ª≠", key="train_models"):
    with st.spinner("ƒêang hu·∫•n luy·ªán c√°c m√¥ h√¨nh..."):
        cache_key = str(len(st.session_state.history)) + str(st.session_state.history[-10:])
        st.session_state.models = train_models(tuple(st.session_state.history), tuple(st.session_state.ai_confidence), cache_key)
    if st.session_state.models is not None:
        st.success("‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng!")

# D·ª± ƒëo√°n
if len(st.session_state.history) >= 6:
    if st.session_state.models is None:
        st.info("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
    else:
        preds, final_score = predict_next(st.session_state.models, st.session_state.history)
        if preds:
            st.session_state.ai_last_pred = "T√†i" if final_score >= 0.5 else "X·ªâu"
            st.subheader(f"üéØ D·ª± ƒëo√°n chung: **{st.session_state.ai_last_pred}** ({final_score:.2%})")
            st.caption("T·ªïng h·ª£p t·ª´ Stacking Model + Pattern Detector:")
            for k, v in preds.items():
                st.write(f"**{k}** ‚Üí {v:.2%}")
else:
    st.warning("C·∫ßn √≠t nh·∫•t 6 v√°n ƒë·ªÉ b·∫Øt ƒë·∫ßu d·ª± ƒëo√°n.")

st.divider()

# Export/Import
col_export, col_import = st.columns(2)
with col_export:
    csv = export_history()
    st.download_button("üì• Export l·ªãch s·ª≠ (CSV)", csv, f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", "text/csv", key="export_history")
with col_import:
    uploaded_file = st.file_uploader("üì§ Import l·ªãch s·ª≠ t·ª´ CSV", type="csv", key="import_file")
    if uploaded_file:
        import_history(uploaded_file)
