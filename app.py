import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, brier_score_loss
from datetime import datetime
import matplotlib.pyplot as plt
import joblib
import io
import os

# ====== Optional: XGBoost ======
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

# ====== Streamlit Config ======
st.set_page_config(page_title="AI D·ª± ƒëo√°n T√†i/X·ªâu", layout="wide")
st.title("üéØ D·ª∞ ƒêO√ÅN T√ÄI/X·ªàU B·∫∞NG TR√ç TU·ªÜ NH√ÇN T·∫†O (AI)")
st.caption("‚ö†Ô∏è ·ª®ng d·ª•ng ph·ª•c v·ª• M·ª§C ƒê√çCH NGHI√äN C·ª®U ‚Äì KH√îNG khuy·∫øn kh√≠ch c·ªù b·∫°c.")

# ====== Constants ======
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# ====== Feature Generator ======
def create_features(history, window=6):
    X, y = [], []
    if len(history) <= window:
        return np.empty((0, window)), np.array([])
    for i in range(window, len(history)):
        seq = [1 if h == "T√†i" else 0 for h in history[i - window:i]]
        X.append(seq)
        y.append(1 if history[i] == "T√†i" else 0)
    return np.array(X), np.array(y)

def plot_history_pie(history):
    df = pd.DataFrame(history, columns=["K·∫øt qu·∫£"])
    counts = df["K·∫øt qu·∫£"].value_counts()
    st.subheader("üìä Th·ªëng k√™ k·∫øt qu·∫£:")
    st.bar_chart(counts)

# ====== Train Models ======
@st.cache_resource
def train_models_hybrid(history_tuple, ai_conf_tuple, use_xgb=True):
    history = list(history_tuple)
    ai_conf = list(ai_conf_tuple)
    xgb = None

    if len(history) < 8:
        return None

    X, y = create_features(history, window=6)
    if X.shape[0] < 6 or len(np.unique(y)) < 2:
        return None

    recent_weight = np.linspace(0.4, 1.0, len(y))
    if ai_conf and len(ai_conf) >= len(y):
        combined = recent_weight * np.array(ai_conf[-len(y):], dtype=float)
    elif ai_conf and len(ai_conf) < len(y):
        pad = np.ones(len(y) - len(ai_conf))
        combined = recent_weight * np.concatenate([pad, np.array(ai_conf, dtype=float)])
    else:
        combined = recent_weight
    combined = np.clip(combined, 0.2, 2.0)

    n_splits = min(4, max(2, X.shape[0] // 6))
    tscv = TimeSeriesSplit(n_splits=n_splits)

    lr = LogisticRegressionCV(cv=tscv, max_iter=1000, class_weight='balanced',
                              scoring='accuracy', random_state=RANDOM_SEED)
    rf = RandomForestClassifier(n_estimators=60, max_depth=6, min_samples_split=8,
                                class_weight='balanced', n_jobs=-1, random_state=RANDOM_SEED)

    learners = [('lr', lr), ('rf', rf)]

    if use_xgb and HAS_XGB:
        try:
            xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss',
                                n_estimators=50, random_state=RANDOM_SEED, n_jobs=1)
            learners.append(('xgb', xgb))
        except Exception:
            xgb = None

    try:
        lr.fit(X, y, sample_weight=combined)
    except Exception:
        lr.fit(X, y)
    rf.fit(X, y, sample_weight=combined)
    if use_xgb and HAS_XGB and xgb is not None:
        try:
            xgb.fit(X, y, sample_weight=combined)
        except Exception:
            xgb.fit(X, y)

    try:
        calibrated_rf = CalibratedClassifierCV(base_estimator=rf, cv='prefit').fit(X, y)
    except Exception:
        calibrated_rf = rf

    estimators_voting = [('lr', lr), ('rf', calibrated_rf)]
    if xgb is not None:
        estimators_voting.append(('xgb', xgb))

    voting = VotingClassifier(estimators=estimators_voting, voting='soft', n_jobs=-1)
    voting.fit(X, y)

    try:
        stack_estimators = [('lr', lr), ('rf', rf)]
        if xgb is not None:
            stack_estimators.append(('xgb', xgb))
        stack = StackingClassifier(
            estimators=stack_estimators,
            final_estimator=LogisticRegression(max_iter=500),
            passthrough=True,
            n_jobs=-1
        ).fit(X, y)
    except Exception:
        stack = voting

    metrics = {}
    if X.shape[0] > 12:
        split = int(0.8 * len(X))
        X_tr, X_te = X[:split], X[split:]
        y_tr, y_te = y[:split], y[split:]
        try:
            pred = voting.predict(X_te)
            metrics['voting_acc'] = float(accuracy_score(y_te, pred))
            pprob = voting.predict_proba(X_te)[:, 1]
            metrics['voting_brier'] = float(brier_score_loss(y_te, pprob))
        except Exception:
            metrics['voting_acc'] = None
            metrics['voting_brier'] = None

    return {
        "voting": voting,
        "stacking": stack,
        "lr": lr,
        "rf": rf,
        "xgb": xgb,
        "metrics": metrics
    }

# ====== Prediction ======
def predict_next(model_dict, history):
    if model_dict is None or len(history) < 6:
        return None, None
    X, _ = create_features(history, window=6)
    last = X[-1].reshape(1, -1)
    model = model_dict["voting"]
    pred = model.predict(last)[0]
    proba = model.predict_proba(last)[0][pred]
    return ("T√†i" if pred == 1 else "X·ªâu"), round(proba, 3)

# ====== Streamlit UI ======
st.sidebar.header("‚öôÔ∏è Tu·ª≥ ch·ªçn")
st.sidebar.markdown("Nh·∫≠p k·∫øt qu·∫£ g·∫ßn ƒë√¢y (T√†i/X·ªâu).")

if "history" not in st.session_state:
    st.session_state.history = []
if "ai_conf" not in st.session_state:
    st.session_state.ai_conf = []

col1, col2 = st.columns(2)
with col1:
    if st.button("‚ûï Th√™m k·∫øt qu·∫£ T√ÄI"):
        st.session_state.history.append("T√†i")
        st.rerun()
with col2:
    if st.button("‚ûñ Th√™m k·∫øt qu·∫£ X·ªàU"):
        st.session_state.history.append("X·ªâu")
        st.rerun()

if st.button("‚Ü©Ô∏è Xo√° k·∫øt qu·∫£ cu·ªëi"):
    if st.session_state.history:
        st.session_state.history.pop()
        st.rerun()

# Hi·ªÉn th·ªã l·ªãch s·ª≠
if st.session_state.history:
    st.write("üßæ **Chu·ªói k·∫øt qu·∫£:**", " ‚Üí ".join(st.session_state.history))
    plot_history_pie(st.session_state.history)

# Hu·∫•n luy·ªán m√¥ h√¨nh
if st.button("üöÄ Hu·∫•n luy·ªán AI"):
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
        models = train_models_hybrid(
            tuple(st.session_state.history),
            tuple(st.session_state.ai_conf),
            use_xgb=True
        )
    if models:
        st.session_state.models = models
        st.success("‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng!")
        st.json(models["metrics"])
    else:
        st.error("‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu ho·∫∑c ch·ªâ c√≥ 1 lo·∫°i k·∫øt qu·∫£!")

# D·ª± ƒëo√°n
if "models" in st.session_state:
    if st.button("ü§ñ D·ª± ƒëo√°n k·∫øt qu·∫£ ti·∫øp theo"):
        pred, conf = predict_next(st.session_state.models, st.session_state.history)
        if pred:
            st.success(f"AI d·ª± ƒëo√°n: **{pred}** (ƒê·ªô tin c·∫≠y: {conf*100:.2f}%)")
            st.session_state.ai_conf.append(conf)
        else:
            st.warning("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n!")

# Xu·∫•t / Nh·∫≠p d·ªØ li·ªáu
st.divider()
st.subheader("üì¶ L∆∞u / N·∫°p d·ªØ li·ªáu")
col3, col4 = st.columns(2)
with col3:
    if st.button("üíæ Xu·∫•t CSV"):
        df = pd.DataFrame(st.session_state.history, columns=["K·∫øt qu·∫£"])
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("T·∫£i file CSV", csv, "history.csv", "text/csv")
with col4:
    uploaded = st.file_uploader("T·∫£i file CSV c√≥ c·ªôt 'K·∫øt qu·∫£'", type=["csv"])
    if uploaded:
        df = pd.read_csv(uploaded)
        if "K·∫øt qu·∫£" in df.columns:
            st.session_state.history = df["K·∫øt qu·∫£"].tolist()
            st.success("‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
        else:
            st.error("‚ö†Ô∏è File kh√¥ng c√≥ c·ªôt 'K·∫øt qu·∫£' h·ª£p l·ªá!")

st.markdown("---")
st.caption("¬© 2025 | ·ª®ng d·ª•ng AI D·ª± ƒëo√°n T√†i/X·ªâu ‚Äì ch·ªâ d√πng cho m·ª•c ƒë√≠ch nghi√™n c·ª©u h·ªçc thu·∫≠t.")
