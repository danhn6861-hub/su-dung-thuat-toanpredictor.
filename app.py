import streamlit as st
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import TimeSeriesSplit
import matplotlib.pyplot as plt
import io
from datetime import datetime

st.set_page_config(page_title="AI D·ª± ƒëo√°n T√†i/X·ªâu N√¢ng Cao", layout="wide")

# ===== Sidebar =====
st.sidebar.markdown("""
### ‚ö†Ô∏è L∆∞u √ù
·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh ch·∫•t gi·∫£i tr√≠ v√† tham kh·∫£o. Kh√¥ng khuy·∫øn kh√≠ch s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch c·ªù b·∫°c ho·∫∑c ƒë·∫ßu t∆∞ th·ª±c t·∫ø.
""")

# ===== Session state =====
for key in ["history", "models", "ai_last_pred", "undo_stack", "pred_history"]:
    if key not in st.session_state:
        st.session_state[key] = []

# ===== H√†m t·∫°o ƒë·∫∑c tr∆∞ng =====
def create_features(history, window=6):
    if len(history) < window + 1:
        return np.empty((0, window)), np.empty((0,))
    X, y = [], []
    for i in range(window, len(history)):
        X.append([1 if x=="T√†i" else 0 for x in history[i-window:i]])
        y.append(1 if history[i]=="T√†i" else 0)
    return np.array(X), np.array(y)

# ===== Hu·∫•n luy·ªán model ri√™ng t·ª´ng model v√† Stacking =====
@st.cache_resource
def train_models_individual(history):
    X, y = create_features(history)
    if len(X)<6: return None
    try:
        models = {
            'LogisticRegression': LogisticRegression(max_iter=500, solver='liblinear'),
            'RandomForest': RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=3, random_state=42),
            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric="logloss", n_estimators=50, max_depth=3, learning_rate=0.1)
        }
        # Hu·∫•n luy·ªán ri√™ng
        for name, model in models.items():
            model.fit(X, y)
        # Stacking v·ªõi TimeSeriesSplit
        estimators = [(n,m) for n,m in models.items()]
        tscv = TimeSeriesSplit(n_splits=3)
        stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=tscv)
        stack.fit(X, y)
        models['Stacking'] = stack
        return models
    except Exception as e:
        st.error(f"L·ªói hu·∫•n luy·ªán: {str(e)}")
        return None

# ===== Pattern Detector 6 v√°n =====
def pattern_detector(history, window=6):
    if len(history) < window*2: return 0.5
    states = {'T√†i':1, 'X·ªâu':0}
    trans = np.zeros((2,2))
    for i in range(1,len(history)):
        prev, curr = states[history[i-1]], states[history[i]]
        trans[prev,curr] +=1
    trans /= np.sum(trans,axis=1,keepdims=True)+1e-6
    last_state = states[history[-1]]
    return trans[last_state,1]

# ===== Pattern Detector 10 v√°n v·ªõi tr·ªçng s·ªë gi·∫£m d·∫ßn =====
def pattern_detector_weighted(history, window=10):
    if len(history)<3:
        return pattern_detector(history)
    actual_window = min(len(history),window)
    recent = history[-actual_window:]
    states = {'T√†i':1,'X·ªâu':0}
    weights = np.linspace(1.5,0.5,actual_window)
    weighted_sum = sum(weights[i]*states[recent[i]] for i in range(actual_window))
    return weighted_sum/sum(weights)

# ===== D·ª± ƒëo√°n t·ª´ng model + t·ªïng h·ª£p =====
def predict_next(models, history):
    if len(history)<6 or models is None: return None
    latest = np.array([[1 if x=="T√†i" else 0 for x in history[-6:]]])
    preds = {}
    for name, model in models.items():
        if hasattr(model,"predict_proba"):
            prob = model.predict_proba(latest)[0][1]
        else:
            prob = float(model.predict(latest)[0])
        preds[name] = prob
    preds['Pattern Detector (6 v√°n)'] = pattern_detector(history)
    preds['Pattern Detector (10 v√°n)'] = pattern_detector_weighted(history)
    # Final t·ªïng h·ª£p
    final_score = 0.5*preds.get('Stacking',0.5)+0.25*preds['Pattern Detector (6 v√°n)']+0.25*preds['Pattern Detector (10 v√°n)']
    return preds, final_score

# ===== Th√™m k·∫øt qu·∫£ + undo + t√≠nh accuracy =====
def add_result(result):
    st.session_state.undo_stack.append(st.session_state.history.copy())
    st.session_state.history.append(result)
    if len(st.session_state.history)>200:
        st.session_state.history=st.session_state.history[-200:]
    # C·∫≠p nh·∫≠t pred_history
    if st.session_state.ai_last_pred is not None:
        st.session_state.pred_history.append({'pred':st.session_state.ai_last_pred,'true':result})

def undo_last():
    if st.session_state.undo_stack:
        st.session_state.history = st.session_state.undo_stack.pop()
        if st.session_state.pred_history:
            st.session_state.pred_history.pop()

def get_accuracy():
    if not st.session_state.pred_history: return None
    correct = sum(1 for x in st.session_state.pred_history if x['pred']==x['true'])
    return correct/len(st.session_state.pred_history)

# ===== Export/Import =====
def export_history():
    df = pd.DataFrame({"K·∫øt qu·∫£": st.session_state.history})
    return df.to_csv(index=False).encode('utf-8')
def import_history(uploaded_file):
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.session_state.history = df["K·∫øt qu·∫£"].tolist()
        st.success("ƒê√£ import l·ªãch s·ª≠!")

# ===== Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n =====
def plot_prediction(preds):
    fig,ax=plt.subplots()
    names=list(preds.keys())
    values=[preds[n]*100 for n in names]
    colors=['blue','orange','green','purple','red','brown']
    ax.barh(names,values,color=colors[:len(names)])
    ax.set_xlim(0,100)
    ax.set_xlabel("X√°c su·∫•t T√†i (%)")
    ax.set_title("D·ª± ƒëo√°n t·ª´ng model & Pattern Detector")
    buf=io.BytesIO()
    fig.savefig(buf,format='png')
    buf.seek(0)
    st.image(buf)

# ===== Giao di·ªán =====
st.title("üéØ AI D·ª± ƒëo√°n T√†i/X·ªâu ‚Äì ML + Pattern Detector")

col1,col2 = st.columns(2)
with col1:
    if st.button("Nh·∫≠p T√†i"): add_result("T√†i")
    if st.button("Nh·∫≠p X·ªâu"): add_result("X·ªâu")
with col2:
    if st.button("‚Ü©Ô∏è Undo"): undo_last()
    uploaded_file=st.file_uploader("Import CSV",type='csv')
    if uploaded_file: import_history(uploaded_file)
    st.download_button("Export CSV",export_history(),f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")

st.divider()

# Hi·ªÉn th·ªã l·ªãch s·ª≠
if st.session_state.history:
    st.write("L·ªãch s·ª≠ g·∫ßn ƒë√¢y:", " ‚Üí ".join(st.session_state.history[-30:]))

# Hu·∫•n luy·ªán model
if st.button("‚öôÔ∏è Hu·∫•n luy·ªán model"):
    st.session_state.models = train_models_individual(st.session_state.history)
    st.success("ƒê√£ hu·∫•n luy·ªán xong!")

# D·ª± ƒëo√°n v√† hi·ªÉn th·ªã
if st.session_state.models and len(st.session_state.history)>=6:
    preds, final_score = predict_next(st.session_state.models, st.session_state.history)
    st.session_state.ai_last_pred = "T√†i" if final_score>=0.5 else "X·ªâu"
    st.subheader(f"üéØ D·ª± ƒëo√°n t·ªïng h·ª£p: {st.session_state.ai_last_pred} ({final_score:.2%})")
    st.caption("D·ª± ƒëo√°n chi ti·∫øt t·ª´ng model + Pattern Detector")
    for k,v in preds.items():
        st.write(f"**{k}** ‚Üí {v:.2%} ({'T√†i' if v>=0.5 else 'X·ªâu'})")
    plot_prediction(preds)

# Hi·ªÉn th·ªã t·ª∑ l·ªá th·∫Øng d·ª± ƒëo√°n
acc = get_accuracy()
if acc is not None:
    st.info(f"T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng sau {len(st.session_state.pred_history)} v√°n: {acc:.2%}")
